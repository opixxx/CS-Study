# 자료구조
# 1. 시간복잡도와 공간복잡도에 대해 설명해 주세요.
### 시간복잡도
입력 크기에 대해 어떠한 알고리즘이 실행되는 걸리는 시간
- 시간이라는 것은 컴퓨터 사양, 언어 차이 등 여러가지 요소에 영향을 받는다.
- 주어진 입력크기를 기반으로 어떠한 로직이 몇번 반복되었는가를 중점을 둔다.

### 공간복잡도
입력 크기에 대해 어떠한 알고리즘이 실행되는데 필요한 메모리 공간의 양

## Big-O, Big-Theta, Big-Omega 에 대해 설명해 주세요.
### Big-O
알고리즘의 시간복잡도, 공간복잡도의 상한을 나타낸다.
- 알고리즘이 얼마나 최악의 경우로 동작할 수 있는지를 분석
### Big-Theta
알고리즘의 시간복잡도, 공간복잡도의 평균을 나나탠다.
### Big-Omega
알고리즘의 시간복잡도, 공간복잡도의 하한을 나타낸다.

## 다른 것을 사용하지 않고, Big-O를 사용하는 이유가 있을까요?
- 최악의 경우를 대비하는 것이 중요하다.
- Big-Theta는 데이터 분포에 의존하고, 정확한 계산이 어렵다.
- Big-Omega는 낙관적 분석에 불과하며 실용성이 떨어진다.
## O(1)은 O(N^2) 보다 무조건적으로 빠른가요?
Big-O 표기법은 계수와 상수는 생략해서 표현한다. 따라서 정확한 실행 시간을 나타내지는 않는다. O(1)이 50번의 실행 횟수를 한다고 한다면 N = 7 까지는 O(N^2)이 더 빠르게 된다.

# 2. 링크드 리스트에 대해 설명해 주세요.
### 링크드 리스트
낭비되는 메모리 없이 딱 필요한 만큼만 메모리를 확보해서 사용하고, 또 앞이나 중간에 데이터를 추가하거나 삭제할 때 효율적인 자료 구조가 노드를 만들고 각 노드를 서로 연결하는 방식이다.

- 노드는 내부에 데이터와 다음 노드에 대한 참조를 가지고 있다.
```java
public class Node {
	Object item; // 데이터
	Node next; // 다음 노드에 대한 참조 값
}
```
- 데이터를 추가할 때 동적으로 필요한 만큼의 노드를 만들어서 연결하면 된다. 따라서 배열과 다르게 메모리 낭비하지 않는다.
**시간복잡도**
- 데이터 추가
  - 마지막에 추가 : O(n)
  - 앞에 추가 : O(1)
  - 중간 추가 : O(n)
- 데이터 삭제
  - 마지막에 삭제 : O(n)
  - 앞에 삭제 : O(1)
  - 중간 삭제 : O(n)
- 인덱스 조회 : O(n)
- 검색 : O(n)
## 일반 배열과, 링크드 리스트를 비교해 주세요.
### 일반 배열
연속된 메모리에 순차적으로 데이터가 저장되어있는 자료구조
인덱스를 사용할 때 최고의 효율이 나온다. 하지만 배열의 크기를 배열을 생성하는 시점에 미리 정해야 한다는 단점이 있다.
**시간복잡도**
- 데이터 추가
  - 마지막에 추가 : O(1)
  - 앞, 중간에 추가 : O(n)
- 데이터 삭제
  - 마지막에 삭제 : O(1)
  - 앞, 중간에 삭제 : O(n)
- 인덱스 조회 : O(1)
- 배열의 순차 검색 : O(n)
### 링크드 리스트
비연속적인 메모리에 데이터가 저장되어있는 자료구조
필요에 따라 크기를 동적으로 저절할 수 있다.
삽입,삭제가 배열보다 유연하지만 검색같은 경우 순차적으로 접근해야하기 때문에 O(n)의 시간복잡도를 가진다.

## 링크드 리스트를 사용해서 구현할 수 있는 다른 자료구조에 대해 설명해 주세요.
### 스택
- push : 새 노드를 리스트의 맨 앞 또는 끝에 추가
- pop : 리스트의 맨 앞 또는 끝 노드를 제거 및 반환

### 큐
- enqueue : 새 노드를 리스트의 끝에 추가
- dequeue : 리스트의 맨 앞 노드를 제거 및 반환
# 3. 스택과 큐에 대해서 설명해 주세요.
### 스택
LIFO 자료구조
- 가장 나중에 들어간 데이터가 먼저 나온다.
- push(데이터를 넣는 연산), pop(데이터를 꺼내는 연산)
### 큐
FIFO 자료구조
- 가장 먼저 들어간 데이터가 먼저 나온다.
- enqueue 연산, dequeue 연산
## 스택 2개로 큐를, 큐 2개로 스택을 만드는 방법과, 그 시간복잡도에 대해 설명해 주세요.
**구현**
첫 번째 stack 은 queue enqueue() 연산을 할 때 사용하고, 두 번째 stack 은 dequeue() 연산을 할 때 사용한다.
1. enqueue() -> stack 1 에 push() 을 하여 데이터를 저장한다.
2. dequeue() -> stack 2 가 비어 있다면 stack 1 에서 pop() 을 하고 stack 2 에 push() 을 해서 stack 1 에 데이터를 stack 2 에 옮긴다. stack 2 에서 pop() 을 해서 dequeue() 연산을 한다.
**시간복잡도**
**enqueue()** -> stack 1 에 push() 를 한번만 하면 된다 O(1)
**dequeue()** 
1. stack 2 가 비어 있는 경우 : stack 1 에 n 개 데이터를 pop() 한 이후에 stack 2 에 push() 을 해야 한다. 따라서 O(2*n) -> O(n) 의 시간복잡도를 가진다.
2. stack 2 가 비어 있지 않은 경우 : stack 2 에서 pop() 만 하면 되기 때문에 O(1) 의 시간복잡도를 가진다.

**구현**
첫 번째 큐는 push() 를 두 번째 큐는 pop() 의 연산을 담당한다.
1. **push()** -> queue 1 enqueue() 해서 데이터를 넣는다.
2. **pop()**
   1. queue 1 에 마지막 요소만 남기고 queue 2 에 데이터를 옮긴다. 
   2. queue 1 에 남은 마지막 요소를 제거하고 반환한다.
   3. queue 1 과 queue 2 를 스왑한다.
**시간복잡도**
**push()** -> queue 1 에 enqueue() 한 번만 하면 되기 때문에 O(1) 의 시간복잡도를 가진다.
**pop()** -> queue 1 에 저장된 데이터  n -1 개를 queue 2로 옮겨야 하기 때문에 O(n-1) -> O(n) 이 된다.
## 시간복잡도를 유지하면서, 배열로 스택과 큐를 구현할 수 있을까요?
**배열로 스택 구현**
배열의 인덱스를 스택의 top 포인터로 이용
- top = -1이면 빈 스택
- top = 배열 길이 - 1이면 꽉 찬 스택
- push : top의 값을 1 늘리고 늘린 top 인덱스를 가리키는 곳에 데이터를 넣는다.
- pop : top 인덱스에 있는 값을 반환하고 top 인덱스 값을 1 줄인다.
**배열로 큐 구현하기**
enqueue : 배열의 끝에 요소를 삽입
dequeue : 배열의 앞에서 요소를 제거

단순한 배열을 사용하면 앞의 요소를 제거할 때 나머지 요소를 한 칸씩 이동해야 하기 때문에 포인터 front, rear를 사용해서 배열의 시작점과 끝을 계속 추적한다.

```java
public void enqueue(int data) { 
	if (size == capacity) { 
		RuntimeException("Queue Overflow");
	}
	rear = (rear + 1) % capacity; // 원형 배열에서 rear를 이동 
	arr[rear] = data; size++; 
}

public int dequeue() { 
	if (size == 0) { // 큐가 비어있는 경우 
		throw new RuntimeException("Queue Underflow"); 
	} 
	int data = arr[front]; 
	front = (front + 1) % capacity; // 원형 배열에서 front를 이동 
	size--; 
	return data; 
}
```

## Prefix, Infix, Postfix 에 대해 설명하고, 이를 스택을 활용해서 계산하는 방법에 대해 설명해 주세요.
### Prefix(전위표기식)
- 연산자가 피연산자 앞에 위치하는 표기법.
- 괄호 없이도 연산 우선순위를 명확히 표현할 수 있다.
### Infix(중위표기식)
- 연산자가 피연산자 사이에 위치하는 방법
- 연산 우선순위를 나타내기 위해서 괄호를 사용한다.
### Postfix(후위표기식)
- 연산자가 피연산자 뒤에 위치하는 방법
- 괄호 없이도 연산 우선순위를 명확히 표현할 수 있다.

### 스택을 활용해서 계산하는 방법
**Postfix**
- 왼쪽에서 오른쪽으로 순회한다.
  - 피연산자는 스택에 push
  - 연산자를 만나면 스택에서 두 개의 피연산자를 꺼내고 연산을 수행하고 결과를 다시 스택에 push
  - 최종적으로 스택에 남은 값이 결과
**Prefix**
Postfix와 과정은 같지만 오른쪽에서 왼쪽으로 순회하며 과정을 진행한다.

**Infix**
스택을 연산자 스택, 피연산자 스택 두 개를 사용한다.

- 왼쪽에서 오른쪽으로 순회한다.
  - 피연산자는 피연산자 스택에 push
  - 연산자는 연산자 스택에 push
    - 연산자 우선순위가 낮으면 스택의 연산자를 계산해서 피연산자 스택에 Push
  - 왼쪽 괄호는 연산자 스택에 Push
  - 오른쪽 괄호를 만나면, 왼쪽 괄호까지 연산자를 계산
- 모든 항목을 처리하고 남아 있는 연산자를 계산

## Deque는 어떻게 구현할 수 있을까요?
자바에서 Deque의 구현체로 ArrayDeque, LinkedList가 있다. 
둘의 차이는 ArrayList vs LinkedList의 차이와 비슷하다. 
ArrayDeque는 내부적으로 동적 배열을 사용하고, LinkedList는 내부적으로 양방향 연결 리스트를 사용한다.

ArrayDeque가 내부적으로 배열을 사용하지만 추가적으로 원형 큐 자료구조를 사용해서 앞 뒤 입력 모두 O(1)의 성능을 제공한다.

ArrayDeque가 모든 면에서 LinkedList보다 성능이 더 좋다.
## (C++ 한정) Deque의 Random Access 시간복잡도는 O(1) 입니다. 이게 어떻게 가능한걸까요?

# 4. 해시 자료구조에 대해 설명해 주세요.
Hash Function을 사용하여 데이터를 저장하고 검색하는 자료구조이다.

### Hash Function
입력된 데이터를 특정한 길이의 고정된 값을 가진 해시 코드로 변환하는 함수이다. 이 값을 해시 테이블의 인덱스로 사용된다. 인덱스를 사용하기 때문에 삽입, 삭제, 검색 시 O(1)의 시간복잡도를 가진다.

## 값이 주어졌을 때, 어떻게 하면 충돌이 최대한 적은 해시 함수를 설계할 수 있을까요?
Load Factor를 관리를 한다. 
Load Factor 를 0.7 이하로 유지하고 이 값을 초과하면 테이블의 크기를 늘리고 기존 데이터를 재해싱을 하는 과정을 통해서 충돌 가능성을 줄인다.
## 해시값이 충돌했을 때, 어떤 방식으로 처리할 수 있을까요?
### 선형 조사법
충돌이 발생하면 해시 테이블에서 비어있는 버켓을 찾는 방법
ht[k] 충돌이 발생하면 ht[k+1]이 비어있는지 확인하고 비어있지 않으면 ht[k+2]을 확인한다. 이런 방식으로 비어있는 공간이 나올 때까지 계속해서 확인하는 방법이다.

**이차 조사법**
선형 조사법과 유사하지만 다음 조사할 위치를 아래 식처럼 결정하는 방법
`(h(k) + inc * inc) mod M` 

**이중 해싱법**
다음에 저장할 위치를 결정할 때 원래 해시 함수와 다른 별개의 해시 함수를 이용하는 방법이다. 이 방법은 항목들을 해시 테이블에 더욱 균일하게 분포시킬 수 있다.

선형 조사법과 이차 조사법은 충돌이 발생하면 해시 값에 어떤 특정 값을 더해서 다음 위치를 얻는다. 따라서 해시 값이 같으면 다음에 조사할 위치도 같게 되는데 이중 해싱법에서는 탐색 키를 참조하여 더해지는 값이 결정된다. 따라서 해시 값이 같더라도 탐색 키가 다르면 서로 다른 조사 순서를 갖게 된다.
### 체이닝
해시 테이블의 구조를 변경해서 각 버켓이 하나 이상의 값을 저장할 수 있도록 하는 방법. 체이닝은 연결리스트를 이용해서 해결한다. 물론 버켓 내에서 원하는 값을 찾기 위해서는 연결리스트를 순차 탐색한다.

<img width="710" alt="스크린샷 2024-10-13 오후 3 19 56" src="https://github.com/user-attachments/assets/e678e58e-81bc-490a-afd1-5acb77fbf5f4" />

## 본인이 사용하는 언어에서는, 어떤 방식으로 해시 충돌을 처리하나요?
자바에서는 해시 충돌이 발생하면 Linked List, Red Black Tree을 활용한 체이닝 기법을 사용해서 처리한다.
충돌이 발생하면 연결 리스트를 활용한 체이닝 기법을 사용하다 특정 임계값을 넘어가면 Red Black Tree를 사용해서 관리하게 된다.
## Double Hashing 의 장점과 단점에 대해서 설명하고, 단점을 어떻게 해결할 수 있을지 설명해 주세요.
**장점**
- 다음으로 조사할 위치를 다른 해시 함수를 이용해서 결정하기 때문에 군집화의 문제가 발생하지 않는다.
- 충돌 가능성이 적고, 성능이 좋다.

## Load Factor에 대해 설명해 주세요. 본인이 사용하는 언어에서의 해시 자료구조는 Load Factor에 관련한 정책이 어떻게 구성되어 있나요?
해싱의 성능을 분석하기 위해서는 해시 테이블의 적재비율(Load Factor)이 중요하다.
적재 비율은 `저장된 항목의 개수 / 해싱 테이블의 버켓의 개수` 이다. 

자바에서 기본 loac factor 는 0.75이며 현재 요소 수가 용량의 75%를 초과할 때 리사이징이 발생한다.
load factor가 임계값을 초과하면 현재 용량의 두 배를 늘려 새로운 용량을 계산한다. 

HashMap은 키의 해시 코드를 새로운 용량을 기준으로 다시 계산하고 새로운 배열에서 해당하는 버켓을 찾고 데이터를 넣는다.

Java 8 이후에서는 하나의 버켓에 있는 데이터 수가 특정 임계값(TREEIFY_THRESHOLD, 기본값 8)에 도달하면 버킷의 내부 구조를 연결리스트에서 Red-Black Tree로 변환한다. 모든 Entry 인스턴스는 TreeNode 인스턴스로 변환된다. 이는 검색 성능을 O(n) -> O(log n) 으로 높이기 위함이다.
버켓의 노드 수가 UNTREEIFY_THRESHOLD 미만으로 줄어들면 다시 연결 리스트로 변환된다. 이는 TreeNode가 Map.Entry 인스턴스보다 더 많은 메모리를 차지기 때문인다.
## 다른 자료구조와 비교하여, 해시 테이블은 멀티스레드 환경에서 심각한 수준의 Race Condition 문제에 빠질 위험이 있습니다. 성능 감소를 최소화 한 채로 해당 문제를 해결할 수 있는 방법을 설계해 보세요.
CAS? concurrentHashMap

# 5. 트리와 이진트리, 이진탐색트리에 대해 설명해 주세요.
### 트리
트리는 값을 가진 노드와 이 노드들을 연결해주는 간선들로 이루어진 자료구조이다.
**특징**
- 트리에는 사이클이 존재할 수 없다.
- 모든 노드는 자료형으로 표현이 가능하다.
- 루트에서 한 노드로 이동하는 경로는 유일하다.
- 노드의 개수가 N개라면 간선의 수는 N-1개를 가진다.
### 이진트리
각 노드의 차수(자식 노드)가 2 이하인 트리
- **정 이진 트리(Full Binary Tree)** : 모든 트리의 자식은 0개나 2개
- **포화 이진 트리(Perfect Binary Tree)** : 모든 리프 노드의 높이가 같고 리프 노드가 아닌 노드는 모두 2개의 자식을 갖는다.
- **완전 이진 트리(Complete Binary Tree)** : 모든 리프노드의 높이가 최대 1 차이가 나고, 모든 노드의 오른쪽 자식이 있으면 왼쪽 자식이 있는 이진 트리이다.

### 이진탐색트리
노드의 왼쪽 자식은 부모보다 작은 값, 오른쪽 자식은 부모보다 큰 값을 가지는 트리
**특징**
- 각 노드의 자식이 2개 이하이다.
- 중복된 노드가 없어야 한다.


## 그래프와 트리의 차이가 무엇인가요?
사이클의 유무가 트리와 그래프의 가장 큰 차이이다. 트리는 사이클이 없고 그래프는 사이클이 존재한다.

## 이진탐색트리에서 중위 탐색을 하게 되면, 그 결과는 어떤 의미를 가지나요?

![img1 daumcdn](https://github.com/user-attachments/assets/2376326a-b11d-4673-9222-8a554a8fb903)

1 -> 7 -> 9 -> 10 -> 11 -> 14 -> 21
정렬된 순서의 결과를 의미한다.
## 이진탐색트리의 주요 연산에 대한 시간복잡도를 설명하고, 왜 그런 시간복잡도가 도출되는지 설명해 주세요.
### 검색/삽입 연산
최악의 경우 트리 높이 만큼 탐색하게 된다. 따라서 O(logN)의 시간복잡도를 가진다.

### 삭제 연산
- 삭제 노드를 탐색하는 시간 O(logN)
- 대체 노드를 찾기 위한 서브 트리를 탐색하는 시간 O(logN)
- 참조값 변경하는 데 O(1)
따라서 O(logN)의 시간복잡도를 가진다.
## 이진탐색트리의 한계점에 대해 설명해주세요.
데이터 편향이 발생할 경우 LinkedListd와 같은 O(N)의 시간복잡도를 가지게 된다.

![img1 daumcdn 2](https://github.com/user-attachments/assets/651e3c63-1ff9-46ad-abcd-9fcc14fd7d40)

## 이진탐색트리의 값 삽입, 삭제 방법에 대해 설명하고, 어떤식으로 값을 삽입하면 편향이 발생할까요?
### 삽입
1. 루트 노드에서 시작해서 삽입할 위치를 찾기 위해 트리를 탐색한다.
2. 탐색을 계속해 적절한 자식 노드가 없을 때까지 이동한다. 빈 자리를 찾으면 그 위치에 삽입한다.
### 삭제
1. 리프 노드 삭제 : 삭제할 노드가 리프 노드라면 단순히 트리에서 제거
2. 자식이 하나인 노드 삭제 : 그 자식 노드가 삭제된 노드의 부모 노드와 연결되도록 한다.
3. 자식이 둘인 노드 삭제 : 
   1. 왼쪽 자식 노드에서 가장 큰 값 노드가 삭제될 노드를 대체한다.
   2. 오른쪽 자식노드에서 가장 작은 값 노드가 삭제될 노드를 대체한다.

정렬된 데이터를 삽입할 경우 한 쪽으로 치우쳐진다.
## 이진탐색트리와 동일한 로직을 사용하면, 삼진탐색트리도 정의할 수 있을까요? 안 된다면, 그 이유에 대해 설명해 주세요.

# 6. 힙에 대해 설명해 주세요.
- 최솟값 또는 최댓값을 빠르게 찾아내기 위해 완전이진트리 형태로 만들어진 자료구조이다.
- 우선순위 큐를 위해서 만들어졌다.
- 반정렬 상태를 유지한다.
  - 부모 노드의 키 값이 자식 노드의 키 값보다 항상 큰(작은) 이진 트리를 말한다.

![17084F504DA9895214](https://github.com/user-attachments/assets/3ec79e6f-f44c-4069-b20a-9f040d946f32)

### 최대 힙
부모 노드의 키 값이 자식 노드의 키 값보다 크거나 같은 완전 이진 트리

### 최소 힙
부모 노드의 키 값이 자식 노드의 키 값보다 작거나 같은 완전 이진 트리
## 힙을 배열로 구현한다고 가정하면, 어떻게 값을 저장할 수 있을까요?
- 특정 위치의 노드 번호는 새로운 노드가 추가되어도 변하지 않는다.
- 구현을 쉽게 하기 위해서 배열의 첫 번째 인덱스인 0 은 사용하지 않는다.
- 루트 노드를 첫 번째 인덱스(1)에 저장하고 부모 노드의 인덱스 기준으로 2i 에 왼쪽 자식 2i + 1에 오른쪽 자식을 저장한다.
- 부모 노드 : 자식 노드 / 2
## 힙의 삽입, 삭제 방식에 대해 설명하고, 왜 이진탐색트리와 달리 편향이 발생하지 않는지 설명해 주세요.
### 힙의 삽입

<img width="736" alt="스크린샷 2025-01-20 오후 3 44 45" src="https://github.com/user-attachments/assets/b2f06176-9c59-4547-9f9a-a810cdf0cb7a" />

1. 인덱스 순으로 가장 마지막 위치에 요소를 삽입
2. 힙의 속성(최대 힙, 최소 힙)에 맞을 때까지 부모와 자식간의 교환을 한다.
### 힙의 삭제

<img width="738" alt="스크린샷 2025-01-20 오후 3 45 15" src="https://github.com/user-attachments/assets/18b15d13-c24a-4365-a796-3d2d2de8fab4" />

1. 루트 노드를 삭제하고 마지막 인덱스 요소를 루트 노드로 이동 시킨다.
2. 힙의 속성에 맞을 때까지 자식 노드와 비교하며 교환한다.
   - 자식 노드 둘 모두 힙 속성에 맞을 경우 더 큰 값(작은 값)과 교환한다.

삽입은 항상 마지막 인덱스에 삭제도 항상 루트 노드를 삭제하기 때문에 편향 발생 X
## 힙 정렬의 시간복잡도는 어떻게 되나요? Stable 한가요?
### 힙 정렬 동작 과정
1. 최대 힙(최소 힙)을 구성
2. 현재 힙 루트는 가장 큰 값을 제거하고, 마지막 요소를 루트 노드로 이동시킨 후 힙의 사이즈를 하나 줄인다.
3. 힙의 사이즈가 1보다 크면 위 과정을 반복한다.

이 과정을 거치면서 최대 값을 하나씩 뽑으면서 정렬한다.

**시간복잡도**
루트 노드의 값을 제거하고 재정렬하는 과정의 시간복잡도는 O(logN)이다.
이 과정을 n번 반복하기 때문에 O(NlogN)의 시간복잡도를 가진다.

**Stable 여부**
힙 정렬은 배열의 원소를 힙 구조로 변환하면서 원소들의 상대적인 순서를 유지하지 않는다. Stable 하지 않는 정렬 방법이다.

![image 2](https://github.com/user-attachments/assets/de39d63b-aa4c-48e5-b295-57390b2411cd)

# 7. BBST (Balanced Binary Search Tree) 와, 그 종류에 대해 설명해 주세요.
### BBST
이진 탐색트리의 경우 한쪽으로 치우치게 되어 최악의 경우 O(n)까지 성능이 저하될 수 있는데 BBST 같은 경우 트리가 불균형해지는 것을 방지하여 검색, 삽입, 삭제 연산 모두 O(logN)의 시간복잡도를 보장한다.

**AVL Tree**
- 각 노드의 왼쪽 서브트리와 오른쪽 서브트리의 높이 차이가 최대 1이 되도록 유지하는 이진 탐색 트리
- 삽입, 삭제 후 트리가 불균형해지면 회전을 통해 균형을 유지한다.
- AVL의 Balance Factor가 항상 -1,0,1이어야 한다.
  - Balance Factor = 왼쪽 서브트리의 높이 - 오른쪽 서브트리의 높이
**Red-Black Tree**
- 노드가 레드 또는 블랙 색상을 가지며, 몇 가지 색상 속성을 통해 트리의 균형을 유지하는 이진 탐색 트리

## Red Black Tree는 어떻게 균형을 유지할 수 있을까요?
삽입/삭제 연산 후 Red-Black Tree의 규칙이 깨질 수 있다. 이 규칙을 복구하기 위해서 회전 및 색상 변경을 사용한다.

## Red Black Tree의 주요 성질 4가지에 대해 설명해 주세요.
- 루트 노드는 항상 검은색이다.
- 빨간색 노드의 자식은 항상 검은색이어야 한다.
- 모든 리프노드(NIL 노다, 즉 널 노드)는 검은색이다.
- 각 노드에서 자손까지의 모든 경로에 있는 검은색 노드의 수는 동일해야 한다.
## 2-3-4 Tree, AVL Tree 등의 다른 BBST 가 있음에도, 왜 Red Black Tree가 많이 사용될까요?

### 상대적으로 적은 회전 횟수
- Red-Black Tree 같은 경우 균형 조건이 덜 엄격하다.
  - 노드의 삽입/삭제 후 최대 2회 회전으로 균형을 유지할 수 있다.
  - AVL 트리 같은 경우 균형 조건이 엄격해 더 많은 회전이 필요할 수 있다.
### 메모리 효율성
- 2-3-4트리 같은 경우 한 노드에 여러 키를 저장해야 하므로 구현이 복잡하고 메모리 관리가 더 어려울 수 있다.
### 빠른 평균 성능
- Red-Black Tree 같은 경우 삽입/삭제 면에서 AVL 트리보다 성능이 더 좋다.
  - 데이터가 빈번히 삽입/삭제가 일어나는 경우 더 적합하다.
 # 8. 정렬 알고리즘에 대해 설명해 주세요.
### 거품 정렬(Bubble Sort)
서로 인접한 두 원소의 대소를 비교하고, 조건에 맞지 않다면 자리를 교환하며 정렬하는 알고리즘

**동작과정**
1. 리스트의 첫 번째 요소와 두 번째 요소를 비교한다. 만약 첫 번째 요소가 두 번째 요소보다 크면 두 요소를 교환한다. 이후 두 번째 요소와 세 번째 요소를 비교하고, 이 작업을 반복해서 리스트 끝까지 반복한다.
2. 첫 번째 반복이 끝나면 가장 큰 요소가 리스트의 마지막 위치로 이동하게 되고 이 요소는 더 이상 움직이지 않는다.
3. 리스트의 마지막 요소를 제외한 나머지 요소에 대해 동일한 과정을 반복한다.
4. 더 이상 교환이 필요하지 않을 때까지 이 과정을 반복하면 오름차순으로 정렬된다.

**시간 복잡도**
정렬이 되어있던 안되어있던 2개의 원소를 계속 비교하기 때문에 최선, 평균, 최악의 경우 모두 시간 복잡도가 O(N^2) 이다.

**장점**
- 구현이 매우 간단하다.
**단점**
- 시간복잡도가 비효율적이다.

### 선택 정렬(Selection Sort)
해당 순서에 원소를 넣을 위치는 이미 정해져 있고, 어떤 원소를 넣을지 선택하는 알고리즘이다.

- 첫 번째 순서에는 첫 번째 위치에 가장 최솟값을 넣는다.
- 두 번째 순서에는 두 번째 위치에 남은 값 중 최솟값을 넣는다.
- …

**동작 과정**
1. 주어진 배열 중에서 최솟값을 찾는다.
2. 그 값을 맨 앞에 위치한 값과 교체한다.
3. 맨 처음 위치를 뺀 나머지 배열을 같은 방법으로 교체한다.
4. 하나의 원소만 남을 떄까지 1~3 과정을 반복한다.

**시간복잡도**
n개의 주어진 배열을 정렬하는데 O(N^2) 의 시간복잡도가 걸린다. 최선, 최악, 평균의 경우 O(N^2)의 시간복잡도로 동일하다.

**장점**
- 구현이 간단하다
- Bubble Sort 와 마찬가지로 정렬하려는 배열 안에서 교환하는 방식이기 때문에 다른 메모리 공간을 필요로 하지 않는다. -> 제자리 정렬(in-place sorting)
**단점**
- 비효율적이다.
- 불안정 정렬이다.

### 삽입 정렬(Insertion Sort)
손 안에 카드를 정렬하는 방법과 유사하다. 새로운 카드를 기존의 정렬된 카드 사이의 올바른 자리를 찾아 삽입함으로써 정렬이 유지되게 된다.

정렬되어 있지 않은 리스트의 첫 번째 숫자가 정렬된 리스트의 어느 위치에 삽입되어야 하는가를 판단한 후 해당 위치에 숫자를 삽입한다. 이러한 삽입 연산을 정렬되어 있지 않은 리스트가 없어질 떄까지 반복한다.

**동작 과정**
첫 번째 요소는 이미 정렬되어 있는 상태라고 간주하고 두 번째 요소부터 마지막 요소까지 하나씩 선택하여 정렬된 리스트 부분에 적절한 위치에 삽입한다.
1. 현재 선택된 요소를 키(key)라고 한다
2. 키를 정렬된 부분의 요소들과 비교하여 키보다 큰 요소들은 한 칸씩 뒤로 민다.
3. 키를 올바른 위치에 삽입한다.
4. 1 ~ 3 과정을 모든 요소가 정렬될 때까지 반복한다.

**시간복잡도**
**최선의 경우(입력 자료가 정렬되어 있는 경우)** 
외부 루프는 n-1 번 실행 되고 각 단계에서는 이동 없이 1번의 비교만 이루어지므로 총 비교 횟수는 O(n-1) -> O(N) 의 시간복잡도를 가지게 된다.

**최악의 경우(입력 자료가 역순일 경우)**
각 단계에 놓인 자료들은 전부 한 칸씩 뒤로 이동 시켜야 한다. 외부 루프의 각 단계마다 i번의 비교를 수행하게 되므로 O(N^2) 의 시간복잡도를 가지게 된다.

#### 장점
- 알고리즘이 단순하다.
- 초기 상태가 대부분 정렬되어 있으면 매우 효율적일 수 있다.
- 정렬하려는 배열 안에서 교환하는 방식이기 때문에 다른 메모리 공간을 필요로 하지 않는다. -> 제자리 정렬(in-place sorting)
- Selection, Bubble Sort 와 같은 O(N^2) 알고리즘과 비교했을 때 상대적으로 빠르다.
#### 단점
- 최악의 경우 시간복잡도가 O(N^2) 으로 비효율적이다
- Bubble, Selection Sort 와 마찬가지로 배열의 길이가 길어질수록 비효율적이다.


### 퀵 정렬(Quick Sort)
퀵 정렬은 불안정 정렬에 속하며, 다른 원소와의 비교만으로 정렬을 수행하는 비교 정렬에 속한다.
분할 정복 알고리즘의 하나로, 평균적으로 매우 빠른 수행 속도를 자랑하는 정렬 방법이다.

**분할 정복**
- 문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략이다. 대개 순환 호출을 이용하여 구현한다.

**동작과정**
1. 리스트 안에 있는 한 요소를 선택한다. 이 원소를 피벗(pivot) 이라고 한다.
2. 피벗을 기준으로 피벗보다 작은 요소들은 모두 피벗의 왼쪽으로, 큰 요소들은 오른쪽으로 옮겨진다.
3. 피벗을 제외한 왼쪽 리스트와 오른쪽 리스트를 다시 정렬한다.
   - 분할된 부분 리스트에 대하여 순환 호출을 이용하여 정렬한다.
   - 부분 리스트에서도 피벗을 다시 정하고 2개의 부분 리스트로 나누는 과정을 반복한다.
4. 부분 리스트들이 더 이상 분할이 불가능할 때까지 반복한다.
   - 리스트의 크기가 0 이나 1이 될 때까지 반복한다.

**시간복잡도**
**최선의 경우**
각 순환 호출 단계의 비교 연산은 O(N) 이고, N이 2의 거듭제곱이라고 가정한다면 순환 호출의 깊이는 logN 이다.  따라서 비교 횟수는 O(logN) 이다. 그러므로 최선의 시간복잡도는 O(NlogN) 이다.

**최악의 경우**
partition() 함수에서 피벗 값이 최소나 최대값으로 지정되어 파티션이 나누어지지 않았을 때, O(N^2)에 시간복잡도를 가지게된다. 즉 입력자료가 정렬되어 있으면 O(N^2) 시간복잡도를 가지게 된다.

#### 장점
- 불필요한 데이터의 이동을 줄이고 먼 거리의 데이터를 교환할 뿐만 아니라, 한 번 결정된 피벗들이 추후 연산에서 제외되는 특성으로 인해 시간복잡도가 O(NlogN)을 가지는 다른 정렬 알고리즘과 비교했을 때도 가장 빠르다.
#### 단점
- 불안정 정렬이다.
- 정렬된 배열에서는 시간복잡도가 O(N^2) 으로 성능이 떨어진다.


### 병합 정렬(Merge Sort)
하나의 리스트를 두 개의 균등한 크기로 분할하고 분할된 부분 리스트를 정렬한 다음, 두 개의 정렬된 부분 리스트를 합하여 전체가 정렬된 리스트가 되게 하는 방법이다. 분할 정복 알고리즘 중 하나이고, 안정 정렬(Stable) 에 속한다.

**동작과정**
1. 리스트의 길이가 0 또는 1이면 이미 정렬된 것으로 본다. 그렇지 않은 경우에는
2. 정렬되지 않은 리스트를 절반으로 잘라 비슷한 크기의 두 부분 리스트로 나눈다.
3. 각 부분 리스트를 재귀적으로 합병 정렬을 이용해 정렬한다.
4. 두 부분 리스트를 다시 하나의 정렬된 리스트로 합병한다.

**시간복잡도**
- 순환 호출의 깊이는 퀵 소트와 마찬가지로 logN 이다. 
- 부분 배열로 나누어지는 단계에서는 비교 연산이나 이동 연산이 수행되지 않는다.
- 병합과정에서 비교 연산과 이동 연산이 수행된다.
  - 하나의 병합 과정에서 최대 n번의 비교 연산이 필요하다. 따라서 한 번의 병합과정에서 최대 비교 연산은 NlogN 이다.
  - 하나의 병합 과정에서 임시 배열에 복사했다가 다시 가져와야 하므로 이동 연산은 총 부분 배열에 들어 있는 요소의 개수가 n인 경우 레코드의 이동이 2n번 발생한다. 따라서 2NlogN 번의 이동 연산이 필요하다
따라서 시간복잡도는 O(3NlogN) -> O(NlogN) 이다.

#### 장점
- 같은 값이 있는 경우 원래의 순서를 유지한다 (안정 정렬)
- 항상 O(NlogN)의 시간복잡도를 보장한다.
- 외부 정렬 가능 : 외부 정렬에서 효율적으로 사용할 수 있다. 대용량 데이터를 정렬할 때 메모리 사용을 최소화 할 수 있다.
#### 단점
- 병합 과정에서 임시 배열이 필요하므로 추가 메모리가 필요하다.
- 데이터 크기가 작을 때는 오버헤드가 커져서 삽입 정렬 같은 간단한 알고리즘 보다 느릴 수 있다.

**병합 정렬은 순차적인 비교로 정렬을 진행하므로, 연결리스트의 정렬이 필요할 때 사용하면 효율적이다.**

### 힙 정렬(Heap Sort)
불안전 정렬에 해당하고, 완전 이진 트리를 기본으로 하는 힙 자료구조르 기반으로한 정렬 방식이다.

**동작과정**
1. 최대 힙을 구성
2. 현재 힙 루트는 가장 큰 값, 루트의 값을 마지막 요소와 교환 후 힙의 사이즈 하나 줄인다.
3. 힙의 사이즈가 1보다 크면 위 과정을 반복한다.

이와 같은 방법으로 최대 값을 하나씩 뽑으면서 정렬하는 것이 힙 정렬이다.

**시간복잡도**
힙 트리의 높이는 완전 이진 트리이므로 logN 이다. 하나의 요소를 삽입, 삭제할 때 logN 만큼 시간이 소모된다.
요소의 개수가 N 개 이므로 시간복잡도는 O(NlogN) 이다.

#### 장점
- 가장 큰 값, 작은 값을 구할 때 유용하다.
- 시간복잡도가 좋은 편이다.
#### 단점
- 불안정 정렬에 속한다.
- 퀵 정렬이나 병합 정렬과 비교했을 때 비교적 느리다.

### 기수 정렬(Radix Sort)
데이터를 낮은 자릿수부터 비교해서 정렬해 가는 정렬 알고리즘이다. 

**동작과정**
1. 정렬하려는 데이터 중 가장 큰 수의 자릿수를 파악한다.
2. 가장 낮은 자릿수부터 높은 자릿수까지 정렬을 진행한다. 각 자릿수에 대해 안정 정렬 알고리즘을 사용해서 데이터을 정렬한다.(계수 정렬)
3. 모든 자릿수에 대해 정렬이 끝나면 전체 데이터가 정렬된 상채가 된다.

**시간복잡도**
O(D * (N + K)) 이다. 여기서 D 는 자릿수, N 은 데이터 수, K 는 기수(숫자에서 십진수 -> 10)

##### 장점
- 데이터의 자릿수가 적고, 값의 범위가 제한적일 때 매우 효율적이다.
- 안정 정렬이다.
#### 단점
- 추가적인 공간이 필요하다.
- 실수, 부동소수점 숫자 등 다양한 데이터 형식에 대해서는 직접적으로 적용하기 어렵다.

### 계수 정렬(Counting Sort)
비교 기반이 아닌 정렬 알고리즘으로, 주어진 배열의 요소들이 특정 범위 내에 있을 경우 효율적으로 동작한다.
데이터의 값을 직접 비교하지 않고, 각 요소의 등장 횟수를 기반으로 정렬한다.

**동작과정**
1. 배열 요소들의 최소값, 최대값을 파악하고, 이 값을 기반으로 범위를 결정한다.
2. 원본 배열의 각 요소가 몇 번 등장하는지를 기록할 수 있는 크기의 계수 배열을 생성한다.
   - 계수 배열의 인덱스는 원본 배열의 요소 값에 대응되고 값은 원본 배열에서의 그 요소의 등장 횟수이다.
3. 각 요소의 누적 합을 계산한다.
   - 원본 배열의 요소를 계수 배열을 참조해서 정렬된 위치에 배치하기 위함이다.
4. 누적 합을 사용하여 원본 배열의 요소를 정렬된 위치에 재배치한다.

**시간복잡도**
O(N+K) 이다. K 는 배열에서의 범위를 의미한다.(계수 배열의 크기)

#### 장점
- 정렬하는 데이터가 특정 범위 내에 있을 때 사용하면 매우 효율적이다.(알파벳, 문자)
- 안정 정렬이다.
#### 단점
- K 값이 매우 클 경우 계수 배열의 크기가 커져 메모리 사용량이 많아질 수 있다.
## Quick Sort와 Merge Sort를 비교해 주세요.
Quick Sort는 pivot을 기준으로 나눠 정렬하는 기법이고, Merge Sort는 자료구조를 분할 후에 합치면서 정렬하는 방법이다. 
Merge Sort는 최악, 평균, 최선일 경우 모두 O(nlogn)의 소요되는 반면에 quick sort는 역순으로 정렬되어 있을 시 pivot의 효과를 볼 수 없어 최악의 경우 O(n^2)의 시간이 소요된다.

## Quick Sort에서 O(N^2)이 걸리는 예시를 들고, 이를 개선할 수 있는 방법에 대해 설명해 주세요.
피벗이 항상 최솟값이나 최댓값으로 선택되는 경우이다. 개선하는 방법으로 피벗 선택 방식을 개선할 수 있다.
- 랜덤 피벗 선택 : 랜덤으로 피벗을 선택하게 되면 최악의 경우가 발생할 확률이 줄어든다.
- 중간값 피벗 선택 : 배열의 첫 번째, 중간, 마지막 요소 중 중간값을 피벗으로 선택하게 되면 최악의 경우가 발생할 확률이 줄어든다.
## Stable Sort가 무엇이고, 어떤 정렬 알고리즘이 Stable 한지 설명해 주세요.
### Stable Sort
같은 값을 가진 입력값들을 입력 순서와 동일하게 정렬하는 것을 말한다.
- Bubble sort, insertion sort, merge sort, radix sort, counting sort가 Stable 하다.
## Merge Sort를 재귀를 사용하지 않고 구현할 수 있을까요?
큐를 이용해서 구현할 수 있다.
```java
public class QueueMergeSort {

    // 큐를 이용한 Merge Sort
    public static void queueMergeSort(int[] arr) {
        // 1. 배열의 각 원소를 개별 큐로 초기화
        Queue<int[]> queue = new LinkedList<>();
        for (int num : arr) {
            queue.add(new int[]{num}); // 각 원소를 길이 1인 배열로 저장
        }

        // 2. 병합 반복
        while (queue.size() > 1) {
            // 두 개의 배열을 병합
            int[] left = queue.poll();  // 첫 번째 배열
            int[] right = queue.poll(); // 두 번째 배열
            int[] merged = merge(left, right);
            queue.add(merged); // 병합 결과를 큐에 추가
        }

        // 3. 최종 병합된 배열을 원본 배열에 복사
        int[] sorted = queue.poll();
        System.arraycopy(sorted, 0, arr, 0, arr.length);
    }

    // 두 배열을 병합하는 함수
    private static int[] merge(int[] left, int[] right) {
        int[] result = new int[left.length + right.length];
        int i = 0, j = 0, k = 0;

        // 병합 작업
        while (i < left.length && j < right.length) {
            if (left[i] <= right[j]) {
                result[k++] = left[i++];
            } else {
                result[k++] = right[j++];
            }
        }

        // 남은 원소 추가
        while (i < left.length) {
            result[k++] = left[i++];
        }
        while (j < right.length) {
            result[k++] = right[j++];
        }

        return result;
    }

    // 배열 출력
    public static void printArray(int[] arr) {
        for (int num : arr) {
            System.out.print(num + " ");
        }
        System.out.println();
    }
}
```


## Radix Sort에 대해 설명해 주세요.
LSD MSD
## Bubble, Selection, Insertion Sort의 속도를 비교해 주세요.
| **알고리즘**           | **최선** | **평균** | **최악** | **교환 횟수** |
|:------------------:|:------:|:------:|:------:|:---------:|
| **Bubble Sort**    | O(n)   | O(n^2) | O(n^2) | 많음        |
| **Selection Sort** | O(n^2) | O(n^2) | O(n^2) | 적음, O(n)  |
| **Insertion Sort** | O(n)   | O(n^2) | O(n^2) | 적음        |

## 값이 **거의** 정렬되어 있거나, 아예 정렬되어 있다면, 위 세 알고리즘의 성능 비교 결과는 달라질까요?

**데이터가 아예 정렬되어 있는 경우**
1. Bubble Sort
   - 한 번의 반복으로 모든 데이터가 정렬되어있음을 확인한다. O(n)
2. Selection Sort
   - 데이터의 상태와 관계없이 항상 O(n^2)
3. Insertion Sort
   - 각 원소를 이미 정렬된 부분에 삽입하지 않아도 된다. O(n)
**데이터가 거의 정렬되어 있는 경우**
1. Bubble Sort
   - 일부 교환이 필요하지만, 교환 횟수가 적으면 O(kn)
2. Selection Sort
3. Insertion Sort
   - 각 원소를 적절한 위치로 삽입, 교환 횟수가 적을수록 빠르다.

## 본인이 사용하고 있는 언어에선, 어떤 정렬 알고리즘을 사용하여 정렬 함수를 제공하고 있을까요?

### Java에서의 정렬 알고리즘
**Arrays.sort()**
1. Primitives 경우
   - Dual Pivot Quick Sort를 사용한다.
2. Objects 경우
   - TimSort를 사용한다.
Quick Sort는 불안정 정렬이고, TimSort는 안정 정렬이다.
객체를 정렬할 경우에는 반드시 Stable해야 하기 때문이다.
**Collecitons.sort()**
- TimSort를 사용한다.

## 정렬해야 하는 데이터는 50G 인데, 메모리가 4G라면, 어떤 방식으로 정렬을 진행할 수 있을까요?

외부 정렬 기법을 사용한다.
1. 데이터를 분할
   - 각 데이터를 4GB 메모리에 적합한 크기로 나눈다.
   - 각 청크를 메모리 내에서 정렬한 뒤 디스크에 임시 파일로 저장한다.
2. 병합 정렬
   - 디스크에 저장된 모든 정렬된 청크를 병합 정렬한다.

![image](https://github.com/user-attachments/assets/7fe56e30-d9eb-4c7d-a7fa-dcc8e813b15e)

# 9. 그래프 자료구조에 대해 설명하고, 이를 구현할 수 있는 두 방법에 대해 설명해 주세요.
### 그래프
정점과 간선으로 이루어진 자료구조로, 정점은 객체를 나타내고 간선은 정점들 간의 관계를 나타낸다.

**구현하는 방법**
1. 인접행렬
   - 정점을 2차원 배열로 표현한다.
   - 배열의 크기는 N X N (N은 정점의 개수)
   - 배열의 요소는 간선의 유무 또는 가중치를 나타낸다.
     - 무방향 그래프 : 대칭 행렬
     - 가중치 그래프 : 간선 가중치를 저장
   - 간선 유무 확인이 O(1)로 빠르다.
   - 간선이 적은 그래프에서는 비효율적이다
2. 인접리스트
   - 각 정점에 연결된 정점들을 저장한다.
   - 리스르틀 사용하여 정점을 키로, 연결된 정점의 리스트를 값으로 저장한다.
   - 간선이 많은 그래프에서 효율적이다.
   - 간선 유무 확인이 평균적으로 O(N) 시간이 걸린다.

## 각 방법에 대해, "두 정점이 연결되었는지" 확인하는 시간복잡도와 "한 정점에 연결된 모든 정점을 찾는" 시간복잡도, 그리고 공간복잡도를 비교해 주세요.
### 인접 행렬

- 주어진 정점이 N개일 때 N X N 배열을 만들어야 하기 때문에 O(N^2)의 공간복잡도를 가진다.
- 두 정점(u, v)이 연결되었는지 확인하기 위해서는 `arr[u][v] == 1` 인지만 확인하면 되므로 O(1)의 시간복잡도를 가진다.
- 정점 u와 연결된 모든 정점을 찾기 위해서는 u번째 row에 대해서 반복분을 돌아 확인하므로 O(N)의 시간복잡도를 가진다.

### 인접 리스트
- 주어진 정점이 N개 간선이 E개라면 N 길이의 리스트를 생성하고 E개 만큼 연결리스트로 연결해주면 되기 때문에 O(N + E) 공간복잡도를 가진다.
- 두 정점(u, v)이 연결되었는지 확인하기 위해서는 `list.get(u)` 을 해서 연결된 정점 중 v 노드가 있는지 찾아야 하기 때문에 O(N) 시간 복잡도를 가진다.
- 정점 u와 연결된 모든 정점을 찾기 위해서는 `list.get(u)`을 해서 모든 정점을 돌며 확인해야 하기 때문에 O(N)의 시간복잡도를 가진다.

## 정점의 개수가 N개, 간선의 개수가 N^3 개라면, 어떤 방식으로 구현하는 것이 효율적일까요?
간선의 개수가 많아 밀집 그래프이다. 밀집 그래프는 인접 행렬로 구현하는 것이 더 효율적인데,
일반적인 인접행렬로 N^3개의 간선은 구현하지 못하기 때문에 인접리스트로 구현해야 한다.
## 사이클이 없는 그래프는 모두 트리인가요? 그렇지 않다면, 예시를 들어주세요.
아니다. 사이클이 없는 그래프라고 해서 트리가 되는 것은 아니다.
트리는 사이클이 없으면서 연결을 유지하는 데 필요한 최소한의 간선만을 가진다. 그리고 모든 노드가 연결되어 있어야 한다.

1. 사이클이 없는 방향 그래프(DAG, Directed Acyclic Graph)

![img1 daumcdn 3](https://github.com/user-attachments/assets/3a707e33-587e-4ab6-8597-93cdb97f1bf6)

2. 모든 그래프가 연결되지 않은 그래프 

![img](https://github.com/user-attachments/assets/e4d8ddf4-5935-43a6-b362-c4ff346a9334)

 # 10. 그래프에서, 최단거리를 구하는 방법에 대해 설명해 주세요.
### BFS
- 무가중치, 무방향 그래프에서 최단거리를 구할 수 있다.
- BFS를 통해 시작 정점에서 모든 정점까지의 최단 거리를 계산한다.
### 다익스트라
- 가중치가 있는 그래프에서 한 정점에서 다른 모든 정점으로의 최단 거리를 구하는 알고리즘
- 가중치가 모두 양수일 때만 가능하다.
- 배열로 구현한 경우 O(V^2), 우선순위 큐로 구현한 경우 O((V + E)logV)
### 플로이드-워셜
- 모든 정점 간의 최단거리를 구해야 할 때
- 그래프가 완전히 연결되지 않아도 동작한다.
- O(V^3) 시간 복잡도를 가지기 때문에 정점의 수가 적을 때 사용한다.

## 트리에서는 어떤 방식으로 최단거리를 구할 수 있을까요? (위 방법을 사용하지 않고)
### LCA(최소 공통 조상)
트리 구조에서 임의의 두 노드가 같은 가장 가까운 조상 노드를 의미한다.
- 트리에서 임의의 노드 u에서 v로 가는 경로는 반드시 u -> LCA -> v의 경로를 가진다.

### 구현방법
**루트부터 탐색하는 방법**
1. 루트에서 시작하여 두 노드 a, b 로 가는 경로를 각각 찾는다.
2. 두 경로에서 마지막으로 일치하는 노드를 찾는다.
3. 그 노드가 최소 공통 조상이다.
시간복잡도는 경로를 찾는데 O(N) 이 걸리고 두 경로를 비교하는데 O(H) 가 걸리므로 전체 시간복잡도는 O(N+H) 이다. (단, H는 트리의 높이)

**이진 탐색으로 찾는 방법**
1. 현재 노드를 루트로 하여 탐색을 시작한다.
2. 만약 현재 노드의 값이 두 노드 a, b 값보다 크다면, 왼쪽 서브트리에서 LCA 를 찾는다.
3. 만약 현재 노드의 값이 두 노드 a, b 값보다 작다면, 오른쪽 서브트리에서 LCA 를 찾는다.
4. 그렇지 않다면 현재 노드가 LCA 다.
시간복잡도는 O(H) 이다. H 는 트리의 높이이고, 최악의 경우 O(N)이 될 수 있다.
## 다익스트라 알고리즘에서, 힙을 사용하지 않고 구현한다면 시간복잡도가 어떻게 변화할까요?
우선순위 큐로 구현한 경우 O((V + E)logV)
배열로 구현을 한 경우 V개의 노드에서 V - 1개의 노드에 대해 검사해야 하므로 O(V^2)의 시간복잡도를 가진다.
## 정점의 개수가 N개, 간선의 개수가 N^3 개라면, 어떤 알고리즘이 효율적일까요?
플로이드 워셜 
## A* 알고리즘에 대해 설명해 주세요. 이 알고리즘은 다익스트라와 비교해서 어떤 성능을 낼까요?
### A* 알고리즘
최단 경로를 효율적으로 찾기 위해 휴리스틱을 사용하는 알고리즘이다. 다익스트라의 확장 버전으로 휴리스틱 정보를 추가하여 목표지점에 더 가까운 경로를 우선적으로 탐색한다.

### 특징
- 다익스트라는 시작점에 모든 노드로의 최단 거리를 계산하지만 A*는 목표 지점을 고려해 더 빠른 최단 경로를 찾습니다.
- 휴리스틱 함수를 사용하여 목표 지점까지의 예상 비용을 추정한다.

다익스트라와 비교해서 탐색 공간을 줄여서 성능을 개선할 수 있지만 휴리스틱의 품질에 크게 의존한다. 부적절한 휴리스틱 함수를 사용 시 다익스트라보다 성능이 나빠질 수 있다.

## 음수 간선이 있을 때와, 음수 사이클이 있을 때 각각 어떤 최단거리 알고리즘을 사용해야 하는지 설명해 주세요.
음수 간선이 있는 경우
- 다익스트라 사용 불가
- 플로이드 워셜, 벨만-포드 알고리즘을 사용
음수 사이클이 있은 경우
- 벨만-포드 알고리즘을 사용해서 음수 사이클의 유무를 체크하며 최단 거리를 구할 수 있다.

# 11. 재귀함수에 대해 설명해 주세요.
### 재귀함수
자기 자신을 호출하는 함수를 말한다. 

### 구조
1. 기저 조건
   - 재귀를 종료하는 조건
   - 기저 조건이 없으면 무한 루프에 빠질 수 있다.
2. 재귀 단계
   - 문제를 더 작은 부분 문제로 나누고, 자기 자신을 호출한다.
### 장단점
- 반복적인 구조를 가진 문제에 적합하다. (분할 정복, 트리 탐색)
- 너무 많은 재귀 호출이 발생하면 스택 오버플로 발생 가능성이 있다.
- 함수 호출이 중첩되어 디버깅이 복잡하다.

## 재귀 함수의 동작 과정을 Call Stack을 활용해서 설명해 주세요.
### 동작 과정
1. 최초로 호출되면 함수 정보가 Call Stack에 쌓인다.
2. 재귀 함수가 자기 자신을 호출하면, 새로운 함수 호출이 Call Stack에 쌓인다. 
3. 재귀 함수가 자기 자신을 여러 번 호출하면 해당 함수의 정보들이 계속해서 Call Stack에 쌓인다.
4. 재귀 함수가 종료 조건에 도달하면, 가장 마지막에 호출된 함수부터 순차적으로 반환되어 Call Stack에서 제거되고, 이전에 호출한 함수들이 차례대로 실행을 재개한다.
5. Call Stack에 쌓였던 모든 함수가 종료되면 함수 호출이 완전히 종료된다.

## 언어의 스펙에 따라, 재귀함수의 최적화를 진행해주는 경우가 있습니다. 어떤 경우에 재귀함수의 최적화가 가능하며, 이를 어떻게 최적화 할 수 있을지 설명해 주세요.

**Tail Recursion** 
마지막으로 호출되는 함수가 최종 결과값을 도출해 더이상 계산을 수행하지 않도록 최적화할 수 있습니다. 이렇게 해서 메모리 오버헤드를 크게 줄일 수 있습니다.
- 재귀 호출이 꼬리 위치에 있어야 한다.
  - 재귀 호출 이후 추가 연산이 없어야 한다. 
  - `return factorial(n-1)` 은 꼬리 위치, `return factorial(n-1) + 1`은 꼬리 위치가 아니다.

**memoization** 
중간 결과값들에 대해 캐싱하여 동일한 계산을 여러번 수행하는 재귀함수를 최적화하는데 사용할 수 있습니다.
# 12. MST가 무엇이고, 어떻게 구할 수 있을지 설명해 주세요.
### MST(최소 신장 트리, Minimum Spanning Tree)
그래프 이론에서 가중치가 있는 연결 그래프의 모든 정점을 포함하며, 간선 가중치의 합이 최소가 되는 신장 트리이다.

**신장 트리**
- 그래프의 모든 정점을 포함하면서 사이클이 없는 부분 그래프
- N개의 정점을 가진 그래프의 신장 트리는 항상 N - 1개의 간선을 가진다.

**특징**
- 그래프가 연결되어 있어야 MST를 구할 수 있다.
- 가중치의 합이 최소가 되어야 한다.
- 여러 MST가 존재할 수 있다.

**MST를 구하는 대표적인 알고리즘**
1. 크루스칼 알고리즘
   - 모든 간선을 가중치 오름차순으로 정렬한 뒤, 가중치가 낮은 간선부터 선택해서 MST를 구축
   - 사이클이 생기지 않도록 간선 선택
   - N - 1개의 간선을 선택하면 종료
   - 사이클 판별을 위해서 Union-Find을 사용한다.
2. 프림 알고리즘
   - 시작 정점에서부터 간선을 하나씩 추가해서 MST를 확장
   - MST에 연결된 정점 중 가장 낮은 가중치의 간선을 선택
   - 우선순위 큐 사용
## Kruskal 알고리즘에서 사용하는 Union-Find 자료구조에 대해 설명해 주세요.
### Union-Find
서로소 집합을 표현하고 관리하는데 효율적인 자료구조이다. 그래프의 사이클 판별, 연결 여부 확인, MST(크루스칼) 등에서 자주 사용된다.

**Find(x)**
- 특정 원소가 속한 집합의 대표 원소(루트)를 찾는다.
- 동일한 집합에 속한 원소들은 모두 동일한 대표 원소를 가진다.
**Union(x, y)**
- 두 원소가 속한 집합을 하나로 합친다.
- 이를 통해 서로 다른 두 집합을 연결할 수 있다.

## Kruskal 과 Prim 중, 어떤 것이 더 빠를까요?
Prim의 시간복잡도는 우선순위 큐에 간선을 삽입하고 추출하는데 O(ElogV)가 걸린다.
-> 정점의 수 V가 적은 경우, 밀집 그래프에서 효율적이다.
Kruskal은 간선 정렬 하는 ElogE, Union-Find 연산 E가 걸려 O(ElogE + ElogV)
-> 간선의 수 E가 적은 희소 그래프에서 효율적이다.
## Kruskal 과 Prim 알고리즘을 통해 얻어진 결과물은 무조건 트리인가요? 만약 그렇다면 증명해 주세요. 그렇지 않다면, 반례를 설명해 주세요.
**Kruskal**
- Union-Find를 통해 사이클을 판별하기 떄문에 사이클이 생기지 않는다.
- N - 1개의 간선을 추가한 뒤 종료 -> 모든 정점이 반드시 연결된다.
**Prim**
- 방문한 정점은 다시 방문하지 않으므로 사이클이 생기지 않는다.
- 모든 정점을 방문할 때까지 반복하고, 모든 정점이 MST에 포함되면 종료한다.

Kruskal, Prim의 결과물로 사이클이 생기지 않고, 모든 노드들이 연결되고, 간선이 N - 1개로 생기기 때문에 무조건 트리가 생긴다.


# 13. Thread Safe 한 자료구조가 있을까요? 없다면, 어떻게 Thread Safe 하게 구성할 수 있을까요?

### synchronized를 대신 적용해주는 프록시를 만드는 방법
List, Set, Map 등 주요 인터페이스를 구현해서 synchronized를 적용할 수 있는 프록시를 만들면 된다.

- `synchronizedXXX()`
  - synchronized를 추가하는 프록시 역할을 한다.
- 단순히 모든 메서드에 synchronized를 걸어버린다고 생각하면 된다.
**단점**
- 동기화 오버헤드가 발생한다. synchronized 키워드가 안전한 동기화를 보장하지만, 각 메서드 호출 시마다 동기화 비용이 발생한다. 이로 인한 성능 저하가 생길 수 있다.
- 전체 컬렉션에 대해 동기화가 이루어지기 때문에 잠금 범위가 넓어질 수 있다. 병렬 처리의 효율성을 저하시키는 요인이 된다.
- 정교한 동기화가 불가능하다. 컬렉션 전체에 동기화가 이루어지지만, 특정 부분이나 메서드에 대해 선택적으로 동기화를 적용하는 것은 어렵다.
### concurrent
동시성을 위한 컬렉션, 더 정교한 잠금 메커니즘을 사용하여 동시 접근은 효율적으로 처리하고, 일부 메서드에 대해서만 동기화를 적용하는 등 유연한 동기화 전략을 제공한다.
- List
  - CopyOnWriteArrayList
- Set
  - CopyOnWriteArraySet (HashSet 대안)
  - ConcurrentSkipListSet (TreeSet 대안, Comparator 사용 가능)
- Map
  - ConcurrentHashMap (HashMap 대안)
  - ConcurrentSkipListMap (TreeMap 대안, Comparator 사용 가능)
- Queue
  - ConcurrentLinkedQueue
- Deque
  - ConcurrentLinkedDeque
synchronized, Lock(ReentrantLock), CAS, 분할 잠금 기술 등 다양한 방법을 섞어서 정교한 동기화를 구현하면서도 동시에 성능을 최적화 한다. Collections.synchronizedXXX를 사용하는 것보다 더 좋은 성능을 제공한다.

## 배열의 길이를 알고 있다면, 조금 더 빠른 Thread Safe 한 연산을 만들 순 없을까요?
?? 

## 사용하고 있는 언어의 자료구조는 Thread Safe 한가요? 그렇지 않다면, Thread Safe 한 Wrapped Data Structure 를 제공하고 있나요?
# 14. 문자열을 저장하고, 처리하는 주요 자료구조 및 알고리즘 (Trie, KMP, Rabin Karp 등) 에 대해 설명해 주세요.

### Trie
문자열에서 검색을 빠르게 도와주는 자료구조이다.

<img width="394" alt="스크린샷 2025-03-11 오전 2 12 04" src="https://github.com/user-attachments/assets/4134d10c-2216-440f-ac8b-1e2f2ca9df74" />

**삽입**
1. 문자열의 첫 번째 문자부터 시작하여, 해당 문자를 나타내는 자식 노드가 루트 노드에 있는지 확인한다.
2. 없다면 새로운 노드를 추가하고, 있다면 다음 문자로 이동한다.
3. 문자열의 끝에 도달하면, 해당 노드에 단어의 끝임을 표시한다.
**검색**
1. 검색하려는 문자열의 첫 번째 문자부터 시작하여, 해당 문자를 나타내는 자식 노드가 있는지 확인합니다.
2. 노드가 없다면 해당 문자열은 트라이에 존재하지 않음을 의미합니다.
3. 마지막 문자까지 노드를 따라간 후, 그 노드에 단어의 끝 표시가 있다면 해당 문자열이 트라이에 존재하는 것입니다.
**장점**
- 빠른 검색 : 문자열의 길이에 비례하여 O(M)의 시간복잡도를 가진다.(M은 문자열의 길이)
- 접두사 검색 : 특정 접두사로 시작하는 모든 단어를 쉽게 찾을 수 있다.
**단점**
- 각 문자를 개별 노드로 저장하기 때문에, 입력되는 단어가 많을질수록 메모리 측면에서 비효율적이다.

### KMP
String Matching을 완전 탐색으로 찾는다면 O(nm)의 시간복잡도를 갖게된다.
KMP, Rabin Karp 방법을 사용하다면 O(n)의 시간복잡도로 구현할 수 있다.

- 패턴 내 접두사와 접미사를 활용해 불필요한 비교를 줄인다.
- `abcabd`의 패턴을 기록하는 배열을 만든다고 하자
  - ()안에 있는 글자들의 접두사, 접미사가 일치하는 가장 긴 길이를 찾으면 된다.
  - (a)bcabd -> 0
  - (ab)cabd -> 0
  - (abc)abd -> 0
  - (abca)bd -> 1
  - (abcab)d -> 접두사 ab, 접미사 ab가 일치하므로 2
  - (abcabd) -> 0
- 패턴과 텍스트가 일치하지 않을 때 패턴 내에서 배열을 참조하여 이미 일치한 부분을 재활용
- 패턴의 접두사와 접미사가 동일한 부분을 활용해 텍스트 포인터는 뒤로 이동하지 않고, 패턴 포인터만 이동
### Rabin Karp
문자열의 해시 값을 계산해 패턴 매칭을 수행한다.
문자 aaaabb, aaaab를 비교한다고 하자
- aaaab의 해시 값이 26이라고 가정하자
- aaaabb 문자를 길이 5로 슬라이딩 윈도우를 통해서 해시 값을 비교한다.
- 해시 값이 같다면 해시 충돌이 발생했을 경우를 고려하여 문자를 비교하고 문자가 같다면 일치, 문자가 다르다면 다시 슬라이딩 윈도우를 통해 해시 값을 비교한다.

# 15. 이진탐색이 무엇인지 설명하고, 시간복잡도를 증명해 보세요.
### 이분 탐색
결정 문제의 답이 이분적일 때 사용할 수 있는 탐색 기법이다. 결정 문제란 답이 Yes or No인 문제를 의미한다.

**시간복잡도**
정렬된 배열에 요소들의 범위를 반씩 좁혀가며 타겟을 찾기 때문에 O(logN)의 시간복잡도를 가진다.


https://www.acmicpc.net/blog/view/109
## Lower Bound, Upper Bound 는 무엇이고, 이를 어떻게 구현할 수 있을까요?

### Lower Bound
주어진 값 이상이 되는 첫 번째 위치를 찾는 것
배열에서 찾고자 하는 값보다 크거나 같은 값이 처음으로 등장하는 위치를 반환한다.
**구현**
- 배열의 중간값이 타겟보다 작으면 `left = mid + 1`
- 배열의 중간값이 타겟보다 크면 `right = mid`
- `while(left < right)` 까지 반복
```java
public static int lowerBound(int[] arr, int target) {
    int left = 0, right = arr.length; // right는 배열 크기
    while (left < right) {
        int mid = left + (right - left) / 2;
        if (arr[mid] >= target) {
            right = mid;
        } else {
            left = mid + 1;
        }
    }
    return left;
}
```

### Upper Bound
주어진 값을 초과하는 첫 번째 위치를 찾는 것
배열에서 찾고자 하는 값보다 큰 값이 처음으로 등장하는 위치를 반환한다.

**구현**
- 배열의 중간값이 타겟보다 작거나 같으면 `left = mid + 1`
* 배열의 중간값이 타겟보다 크면 `right = mid`
- `while(left < right)` 까지 반복
```java
public static int upperBound(int[] arr, int target) {
    int left = 0, right = arr.length; 
    while (left < right) {
        int mid = left + (right - left) / 2;
        if (arr[mid] > target) {
            right = mid; 
        } else {
            left = mid + 1;
        }
    }
    return left;
}
```
## 이진탐색의 논리를 적용하여 삼진탐색을 작성한다고 가정한다면, 시간복잡도는 어떻게 변화할까요? (실제 존재하는 삼진탐색 알고리즘은 무시하세요!)
배열을 매 실행마다 1/3 등분을 하여 두 개의 중간 지점을 설정해 탐색하기 때문에 시간복잡도는 O(log3_N)이다.
- 삼진 탐색이 이진 탐색보다 비교 횟수가 많다.
  - 이진 탐색을 한 단계에서 1번 비교, 삼진 탐색은 한 단계에서 2번 비교
- 이진 탐색이 삼진 탐색보다 더 효율적이다.

## 기존 이진탐색 로직에서 부등호의 범위가 바뀐다면, (ex. <= 라면 <로, <이라면 <= 로) 결과가 달라질까요?
`if (arr[mid < target)` -> Lower Bound를 계산하는 로직
`if (arr[mid] <= target)` -> Upper Bound를 계산하는 로직

# 16. 그리디 알고리즘과 동적 계획법을 비교해 주세요.
### 그리디 알고리즘
지금 가장 최적인 답을 근시안적으로 택하는 알고리즘 -> 관찰을 통해 탐색 범위를 줄이는 알고리즘

### DP
문제를 작은 하위 문제로 나누고 하위 문제의 결과를 저장하여 동일한 계산을 반복하지 않음으로써 최적 해를 구하는 알고리즘

## 그렇다면, 어떤 경우에 각각의 기법을 사용할 수 있을까요?
- 탐욕적 선택 속성 : 앞의 선택이 이후의 선택에 영향을 주지 않는다.
- 최적 부분 구조 : 문제에 대한 최종 해결 방법은 부분 문제에 대한 최적 문제 해결 방법으로 구성된다.

**그리디 알고리즘**
탐욕적 선택 속성, 최적 부분 구조가 만족할 때 사용할 수 있다.
**DP**
최적 부분 구조, 중복된 하위 문제 특성을 만족할 때 사용할 수 있다.
## 그렇다면, 동적 계획법으로 풀 수 있는 모든 문제는 재귀로 변환하여 풀 수 있나요?
DP로 풀 수 있는 문제는 재귀로 풀 수 있다. 하지만 재귀만 사용할 경우 중복 계산과 스택 오버플로 같은 성능 문제를 초래할 수 있다.
