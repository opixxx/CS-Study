# 데이터베이스
> [VSFe/Tech-Interview](https://github.com/VSFe/Tech-Interview)

# 1. Key (기본키, 후보키, 슈퍼키 등등...) 에 대해 설명해 주세요.

**Key**
튜플을 유일하게 식별할 수 있는 속성의 집합
- 후보키
  - 테이블에서 각 행을 유일하게 식별할 수 있는 최소한의 속성들의 집합
  - 기본키가 될 수 있는 후보들이며, **유일성**과 **최소성**을 동시에 만족해야 함
- 슈퍼키
  - 유일성은 만족하지만 최소성은 만족하지 못하는 키
- 기본키
  - 후보키 중 선택된 키
- 대체키
  - 후보키 중 기본키로 결정된 키를 제외한 나머지 키
- 외래키
  - 한 테이블이 다른 테이블의 기본키를 참조해서 테이블 간에 관계를 만드는 키
  
## 기본키는 수정이 가능한가요?

이론적으로 기본키 값을 수정하는 것은 가능한다. 하지만 권장하지 않는다.
- 기본키가 참조되는 외래 키가 있을 경우 외래 키 제약 조건(참조 무결성)을 위반할 수 있다.
- 데이터 간의 일관성이 깨질 가능성이 있다.

## 사실 MySQL의 경우, 기본키를 설정하지 않아도 테이블이 만들어집니다. 어떻게 이게 가능한 걸까요?
 
**InnoDB 클러스터링 인덱스**
1. 기본 키가 있는 경우
   - InnoDB 테이블은 기본 키를 기준으로 데이터를 클러스터링하여 저장한다. 
   - 기본 키 값의 순서대로 데이터가 디스크에 정렬되어 저장된다. 
   - 이를 클러스터링 인덱스라 한다.
2. 기본 키가 없는 경우
   - NOT NULL 제약이 있는 유니크 인덱스 : 테이블에 NOT NULL 제약 조건이 적용된 유니크 인덱스가 존재한다면, 그 중 첫 번째 인덱스를 클러스터링 키로 사용한다.
   - 숨겨진 행 ID 생성 : 위 조건을 만족하는 유니크 인덱스가 없으면 InnoDB는 내부적으로 6바이트 크기의 숨겨진 행 ID를 생성하여 각 행을 고유하게 식별하고, 이를 클러스터링 키로 사용한다.

> [\[MySQL :: MySQL 8.4 Reference Manual :: 15.1.20.11 Generated Invisible Primary Keys\]\(￼\)](https://dev.mysql.com/doc/refman/8.4/en/innodb-index-types.html)

## 외래키 값은 NULL이 들어올 수 있나요?
참초 테이블의 외래키 값을 명시적으로 NOT NULL을 지정하지 않으면 NULL 값이 들어올 수 있다.
외래키 값을 참조하는 레코드가 없는 경우에 NULL 값을 가질 수 있다.

## 어떤 칼럼의 정의에 UNIQUE 키워드가 붙는다고 가정해 봅시다. 이 칼럼을 활용한 쿼리의 성능은 그렇지 않은 것과 비교해서 어떻게 다를까요?

### 검색, 조회 성능
UNIQUE가 붙은 경우
- 유니크 인덱스는 B-Tree 구조로 저장되므로 검색 성능이 크케 향상된다.

UNIQUE가 없는 경우
- full table scan으로 데이터를 조회할 수 있다.

### 삽입 성능
UNIQUE가 붙은 경우
- 추가적인 중복 검사 비용이 발생한다.
- 삽입하려는 값이 이미 존재하는 값인지 확인하기 위해 유니크 인덱스를 검색해야 하므로 삽입 성능이 다소 저하될 수 있다.
UNIQUE가 없는 경우
- 중복 검사 과정이 없으므로 단순히 데이터 삽입만 하면 된다.

### 수정 성능
UNIQUE가 붙은 경우
- 수정하려는 값이 중복되는지 확인 과정이 필요하다
UNIQUE가 없는 경우
- 중복 검사 과정이 필요없다.

### 삭제 성능
UNIQUE가 붙은 경우
- 유니크 인덱스를 통해 해당 데이터를 빠르게 찾아 삭제할 수 있다.
- 삭제 대상이 고유하기 때문에 테이블 스캔 없이 가능하다.
UNIQUE가 없는 경우
- 특정 조건을 만족하는 데이터를 삭제할 때 테이블 스캔이 필요할 수 있다.


# 2. RDB와 NoSQL의 차이에 대해 설명해 주세요.
![img1 daumcdn](https://github.com/user-attachments/assets/ef1c8c4e-fb5e-4d7f-afc4-bcb0b70495ff)

## NoSQL의 강점과, 약점이 무엇인가요?
강점
- 스키마리스 구조이기 때문에 다양한 형태의 데이터를 쉽게 저장할 수 있어 비정형 데이터나 구조가 자주 변경되는 데이터 처리에 적합하다.
- 수평적 확장이 용이하여 여러 서버에 데이터를 분산하여 처리할 수 있다.
약점
- 데이터 중복이 발생할 수 있다.
- 트랜잭션을 ACID 수준으로 보장하지 않으므로 데이터 무결성이 강하지 않다.
- SQL 기반의 복잡한 쿼리를 지원하지 않는 경우가 많아 조인, 복잡한 쿼리 등이 어렵거나 불가능하다.

## RDB의 어떠한 특징 때문에 NoSQL에 비해 부하가 많이 걸릴 "수" 있을까요? (주의: 무조건 NoSQL이 RDB 보다 빠르다라고 생각하면 큰일 납니다!)
정규화된 스키마로 인해 여러 테이블을 조인하여 데이터를 조회해야 하는 경우가 있다.
이러한 조인 연산이 성능이 부하를 줄 수 있다.

## NoSQL을 활용한 경험이 있나요? 있다면, 왜 RDB를 선택하지 않고 해당 DB를 선택했는지 설명해 주세요.
유저 매칭 기능을 구현할 때 Redis를 사용해서 구현했다.
매칭 기능 특성상 읽기 쓰기가 매우 많은 구조였기 때문에 RDB 보다 인메모리 Redis가 성능에 더 좋을 것이라고 생각해서 사용했다.
# 3. 트랜잭션이 무엇이고, ACID 원칙에 대해 설명해 주세요.
**트랜잭션**
하나의 논리적인 작업 단위 
데이터의 일관성과 무결성을 유지하는 데 필수적인 요소다.

ACID 원칙
- Atomicity(원자성) : 트랜잭션이 데이터베이스에 모두 반영되거나, 전혀 반영되지 않아야 함
- Consistency(일관성) : 트랜잭션이 실행되기 전과 후에 데이터베이스가 일관된 상태를 유지해야 함
- Isolation(독립성) : 동시에 실행되는 트랜잭션이 서로 영향을 주지 않아야 함
- Durability(지속성) : 성공적으로 완료된 트랜잭션의 결과가 영구적으로 반영되어야 함

## ACID 원칙 중, Durability를 DBMS는 어떻게 보장하나요?
트랜잭션의 지속성을 보장하려면 시스템에 장애가 발생했을 때 데이터베이스를 원래 상태로 복구하는 회복 기능이 필요하다.

**덤프**나 **로그**방법을 사용해 데이터를 복사해두었다가 회복시킬 때 복사본을 사용한다.

**덤프** 
- 데이터베이스 전체를 다른 저장 장치에 주기적으로 복사하는 방법
- 하루에 한 번 또는 한 달에 한 번과 같이 미리 정해진 주기에 따라 수행한다.
- 디스크와 같은 비휘발성 장치에 복사본을 저장한다.
**로그** 
- 데이터베이스에서 변경 연산이 실행될 때마다 데이터를 변경하기 이전 값과 변경한 이후의 값을 별도의 파일에 기록하는 방법

덤프나 로그 방법으로 데이터를 복구하는 가장 기본적인 방법은 **redo**, **undo** 연산을 실행하는 것이다.

redo : 가장 최근에 저장한 데이터베이스 복사본을 가져온 후 로그를 이용해 복사본이 만들어진 이후에 실행된 모든 변경 연산을 재실행하여 장애가 발생하기 직전의 데이터베이스 상태로 복구(전반적으로 손상된 경우에 주로 사용)

undo : 로그를 이용해 지금까지 실행된 모든 변경 연산을 취소하여 데이터베이스를 원래의 상태로 복구(변경 중이었거나 이미 변경된 내용만 신뢰성을 잃은 경우에 주로 사용)

### 로그 회복 기법
- **즉시 갱신 회복 기법** : 트랜잭션 수행 중에 데이터를 변경한 연산의 결과를 데이터베이스에 즉시 반영한다.
- **지연 갱신 회복 기법** : 트랜잭션이 수행되는 동안에는 데이터 변경 연산의 결과를 데이터베이스에 즉시 반영하지 않고 로그 파일에 기록해두었다가, 트랜잭션이 부분 완료된 후에 로그에 기록된 내용을 이용해 데이터베이스에 한 번에 반영
### 검사 시점 회복 기법
로그 회복 기법과 같은 방법으로 로그 기록을 이용하되, 일정 시간 간격으로 검사 시점(checkpoint)을 만들어둔다. 그리고 장애가 발생하면 가장 최근 검사 시점 이전의 트랜잭션에는 회복 작업을 수행하지 않고, 이후의 트랜잭션에만 회복 작업을 수행한다.

### 미디어 회복 기법
전체 데이터베이스의 내용을 일정 주기마다 다른 안전한 저장 장치에 복사해두는 덤프를 이용한다.
디스크 장애가 발생하면 가장 최근에 복사해둔 덤프를 이용해 장애 발생 이전의 일관된 데이터베이스 상태로 복구한다. 그런 다음 필요에 따라 로그의 내용을 토대로 redo 연산을 실행한다.

## 트랜잭션을 사용해 본 경험이 있나요? 어떤 경우에 사용할 수 있나요?

## 읽기에는 트랜잭션을 걸지 않아도 될까요?

읽기 작업에서 보통 트랜잭션을 안걸었는데(readonly = ture) 특정 읽기 작업에서 트랜잭션을 걸어야 하는 경우도 있는 것 같습니다.
읽기 작업에서 트랜잭션을 걸어야하는 구체적인 상황이 있을까요?(마땅한 상황이 생각이 안나서 와닿지가 않습니다.)

 # 4. 트랜잭션 격리 레벨에 대해 설명해 주세요
### 트랜잭션 격리 레벨
여러 트랜잭션이 동시에 처리될 때, 특정 트랜잭션이 다른 트랜잭션에서 변경하거나 조회하는 데이터를 볼 수 있게 허용할지 여부를 결정하는 것

#### 트랜잭션 격리 수준에 따른 문제점
| 격리 수준            | DIRTY READ | NON-REPEATABLE READ | PHANTOM READ |
|:----------------:|:----------:|:-------------------:|:------------:|
| READ UNCOMMITTED | O          | O                   | O            |
| READ COMMITTED   |            | O                   | O            |
| REPEATABLE READ  |            |                     | O            |
| SERIALIZABLE     |            |                     |              |
**READ UNCOMMITTED**
- 커밋하지 않은 데이터를 읽을 수 있다.
- 트랜잭션 1이 데이터를 수정하고 있는데 커밋하지 않아도 트랜잭션 2가 수정 중인 데이터를 조회할 수 있다. -> DIRTY READ
  - 트랜잭션 2가  DIRTY READ 한 데이터를 사용하는데 트랜잭션 1이 롤백하면 데이터의 정합성에 문제가 발생할 수 있다.
**READ COMMITED**
- 커밋한 데이터만 읽을 수 있다. -> DIRTY READ가 발생하지 않는다.
- 트랜잭션 1이 회원 A를 조회 중인데 갑자기 트랜잭션 2가 회원 A를 수정하고 커밋하면 트랜잭션 1이 다시 회원 A를 조회했을 때 수정된 데이터가 조회된다. -> NON-REPEATABLE READ

**REPEATABLE READ**
- 한 번 조회한 데이터를 반복해서 조회해도 같은 데이터가 조회된다.
- 트랜잭션 1이 다시 10살 이하의 회원을 조회했는데 트랜잭션 2가 5살 회원을 추가하고 커밋하면 트랜잭션 1이 다시 10살 이하의 회원을 조회했을 때 회원 하나가 추가된 상태로 조회된다. -> PHANTOM READ 

**SERIALIZABLE**
- 가장 엄격한 트랜잭션 격리 수준
- DIRTY READ, NON-REPEATABLE READ, PHANTOM READ 가 발생하지는 않지만 동시성 처리 성능이 떨어진다
## 모든 DBMS가 4개의 레벨을 모두 구현하고 있나요? 그렇지 않다면 그 이유는 무엇일까요?

### Oracle
- READ COMMITTED, SERIALIZABLE을 지원한다.
- 기본 격리 수준은 READ COMMITTED 이다.
- READ COMMITTED는 락을 사용하지 않고, 쿼리 시작 지점의 UNDO 데이터를 제공하는 방식으로 구현한다.
- REPEATABLE READ는 지원하지 않지만, for update 절을 이용해 구현이 가능하다.

### MySQL
- 4개의 격리 수준을 모두 지원한다.
- 기본 격리 수준은 REPEATABLE READ 이다.
- InnoDB 스토리지 엔진에서 REPEATABLE READ를 사용하면 Gap Lock 과 Next-Key Lock으로 Phantom Read를 방지할 수 있다.

## 만약 MySQL을 사용하고 있다면, (InnoDB 기준) Undo 영역과 Redo 영역에 대해 설명해 주세요.
### Undo 영역
데이터 변경 이전의 상태를 저장하는 공간
- 트랜잭션의 롤백 대비용
- 트랜잭션의 격리 수준을 유지하면서 높은 동시성을 제공

### Redo 영역
데이터 변경 후의 상태를 저장하는 공간
- 커밋된 이후에 데이터를 복구하는 데 사용
- 데이터 무결성을 보장
- WAL 지원
  - 변경 내용이 데이터 파일에 기록되기 전에 Redo 로그에 먼저 기록된다.
## 그런데, 스토리지 엔진이 정확히 무엇을 하는 건가요?
서버엔진이 필요한 데이터를 물리적인 장치에서 가져오는 역할
데이터의 저장과 관리의 구체적인 동작을 수행하며, 데이터의 저장 방식, 검색, 트랜잭션 처리, 복구를 효율적으로 수행하는 데 중점을 둔다.

- 서버 엔진과 다르게 여러 개를 동시에 사용할 수 있다.
- InnoDB, MyISAM 등

 # 5. 인덱스가 무엇이고, 언제 사용하는지 설명해 주세요
**인덱스**
> 인덱스 == 정렬
- RDBMS에서 검색 속도를 높이기 위한 기술
- 지정한 컬럼들을 기준으로 메모리 영역에 일종의 목차를 생성하는 것

## 일반적으로 인덱스는 수정이 잦은 테이블에선 사용하지 않기를 권합니다. 왜 그럴까요?
수정 작업은 해당 인덱스를 DELETE 한 후 다시 INSERT하는 과정으로 동작한다.
B-Tree 구조 상 인덱스를 변경 작업은 많은 비용이 들기 때문에 수정이 잦은 컬럼에 사용하면 성능상 안좋을 수 있다.

## 앞 꼬리질문에 대해, 그렇다면 인덱스에서 사용하지 않겠다고 선택한 값은 위 정책을 그대로 따라가나요?

## ORDER BY/GROUP BY 연산의 동작 과정을 인덱스의 존재여부와 연관지어서 설명해 주세요.

### ORDER BY 
인덱스가 있는 경우
- 정렬 대상 컬럼이 인덱스가 있다면 이미 정렬된 상태이므로 추가적인 정렬 작업이 필요없다.

인덱스가 없는 경우
- 정렬을 위해 모든 데이터를 메모리(sort buffer)에 적재하거나 외부정렬을 수행해야 한다.

### GROUP BY
인덱스가 있는 경우
- 인덱스를 통해 이미 정렬된 데이터를 사용해서 그룹화할 수 있다. 
- 인덱스를 통해 그룹화 키를 빠르게 찾고 각 그룹에 속하는 행들을 효율적으로 집계할 수 있다.

인덱스가 없는 경우
- 테이블을 풀 스캔해서 데이터를 읽고, 메모리에 로드한 후 정렬 작업을 수행하고 그룹화를 위한 추가 연산을 수행해야 한다.
[1. 커버링 인덱스 \(기본 지식 / WHERE / GROUP BY\)](https://jojoldu.tistory.com/476)
## 기본키는 인덱스라고 할 수 있을까요? 그렇지 않다면, 인덱스와 기본키는 어떤 차이가 있나요?
**기본키**
개념적인 값으로 레코드의 유일성을 보장하는 것

**인덱스**
레코드의 유일성을 보장하지 않고, 검색을 빠르게 해주는 역할을 함
- 별도의 공간에 저장된다.

MySQL InnoDB 같은 경우 기본키에 자동으로 클러스터드 인덱스를 적용해주기 때문에 기본키를 인덱스라고 혼동하는 경우가 있는 것 같다. 모든 데이터베이스가 기본키에 자동으로 클러스터드 인덱스를 적용해주는 것은 아니다.
## 그렇다면 외래키는요?

## 인덱스가 데이터의 물리적 저장에도 영향을 미치나요? 그렇지 않다면, 데이터는 어떤 순서로 물리적으로 저장되나요?
**클러스터드 인덱스**
> 데이터가 물리적으로 정렬되는 방식을 정의하는 인덱스

**비클러스터드 인덱스**
> 테이블 내 데이터의 물리적 순서를 변경하지 않는다.

클러스터드 인덱스가 있는 경우 클러스터드 인덱스 키 값 순서에 따라 물리적으로 저장된다.
만약 없는 경우 일반적으로는 삽입된 순서대로 물리적으로 저장된다.
1. InnoDB
   - 기본키를 클러스터드 인덱스로 자동 적용 -> 기본키 값의 순서에 따라 물리적으로 저장
   - 기본키가 없다면 유니크 값으로 유니크 값도 없다면 내부적으로 생성한 row_id 값을 클러스터드 인덱스로 적용한다.
2. MyISAM
   - 데이터가 삽입된 순서대로 물리적으로 저장
3. PostgreSQL
   - 데이터가 삽입된 순서대로 물리적으로 저장
4. SQL Server
   - 기본키가 클러스터드 인덱스인 경우 기본키 순서대로 저장
   - 아니라면 데이터 삽입 순서로 저장
## 우리가 아는 RDB가 아닌 NoSQL (ex. Redis, MongoDB 등)는 인덱스를 갖고 있나요? 만약 있다면, RDB의 인덱스와는 어떤 차이가 있을까요?
### Redis
- 키-값 저장소
- 기본적으로 키를 인덱스로 사용

### MongoDB

## (A, B) 와 같은 방식으로 인덱스를 설정한 테이블에서, A 조건 없이 B 조건만 사용하여 쿼리를 요청했습니다. 해당 쿼리는 인덱스를 탈까요?
복합 인덱스는 인덱스를 정의한 순서에 따라 작동한다.
index : A,B 로 정의했다면 인덱스는 먼저 A를 기준으로 정렬된 후 B를 기준으로 정렬된다.

1. 쿼리에 A와 B 모두 포함된 경우
`SELECT * FROM table WHERE A = XX AND B = XX;`
인덱스가 타는 쿼리이다.
2. 쿼리에 A만 포함된 경우
`SELECT * FROM table WHERE A = XX;`
인덱스가 타는 쿼리이다.
3. 쿼리에 B만 포함된 경우
`SELECT * FROM table WHERE B = XX;`
인덱스를 타지 않는다.

- 추가적으로 복합 인덱스를 정의할 경우 카디널리티가 높은순에서 낮은순으로 구성하는 것이 더 성능이 좋다
  - 카디널리티가 높다 -> 중복도가 낮다.
- BETWEEN, LIKE, <, > 등의 범위 조건은 해당 컬럼은 인덱스를 타지만 그 뒤 인덱스 컬럼들은 인덱스가 사용되지 않는다.
  - A,B,C 로 인덱스가 정의되어있는데 조회 쿼리를 `WHERE A = XX AND C = XX AND B > YY` 로 조회하면 C는 인덱스가 사용되지 않는다.
# 6. RDBMS, NoSQL에서의 클러스터링/레플리케이션 방식에 대해 설명해 주세요.<!-- {"fold":true} -->
### Clustering
여러 개의 데이터베이스를 수평적인 구조로 구축하는 방식

**동작 과정**
1. 하나의 노드(A)에 쓰기 트랜잭션이 수행되고 commit 된다.
2. 실제 디스크에 데이터를 쓰기 전, 다른 노드(B)로 데이터의 복제를 요청한다.
3. 다른 노드에서 복제 요청을 수락했다는 신호를 보내고, 디스크에 쓰기를 시작한다.
4. A는 B로부터 신호를 받으면 실제 디스크에 데이터를 저장한다.

클러스터링에 종류로는 Active & Active, Active & Stand-by 방식이 있다.
**Active & Active Clustering**
![image](https://github.com/user-attachments/assets/42ca487d-b295-4fc9-a6df-6d1f72d0b2d9)

각 서버를 Active 상태로 두는 방식
- 서버 하나가 죽어도 다른 서버가 역할을 바로 수행하여 중단되는 시간이 없다.
- 여러 대의 서버가 하나의 스토리지를 공유하므로 병목현상이 발생할 수 있다.

**Active & Stand-by Clustering**
![image 2](https://github.com/user-attachments/assets/13f38131-3d5b-44e2-b88f-c31e6cdcae5a)

Active 상태의 서버와 Stand-by 상태의 서버를 나누어 운영하는 방식
- Active 상태의 서버가 문제가 발생한 경우 Stand-by 를 Active로 전환하여 사용한다.
- 병목 현상을 해결할 수 있다.
- 전환하는 시간 동안 서비스를 사용할 수 없게 된다.

### Replication
DB를 복제해서 여러 대의 DB 서버에 저장하는 방식
![3 2](https://github.com/user-attachments/assets/78375239-a6f3-4d51-8c97-1fbb04148a90)

- 마스터 노드는 쓰기 작업만 처리하고 슬레이브 노드는 읽기 작업만 처리함
- DB 요청의 60~80%는 읽기 작업이므로 레플리케이션만으로도 충분히 성능을 높일 수 있다.
- 비동기 방식으로 운영되어 지연 시간이 없다.
- 노드들 간의 데이터 동기화가 보장되지 않아 일관성있는 데이터를 얻지 못할 수 있다.

**동작 과정**
1. 마스터 노드에 쓰기 트랜잭션이 수행됨
2. 마스터 노드는 데이터를 저장하고 트랜잭션에 대한 로그를 Binary Log 에 기록
3. 슬레이브 노드의 I/O Thread는 마스터 노드의 Binary Log를 Relay Log에 복사한다.
4. 슬레이브 노드의 SQL Thread는 Relay Log를 한 줄씩 읽으며 데이터를 저장한다.
![image 3](https://github.com/user-attachments/assets/0ed72449-b088-40b7-aea0-27d6efc3649a)

[RDBMS의 레플리케이션 전략](https://coding-review.tistory.com/522)

## 이러한 분산 환경에선, 트랜잭션을 어떻게 관리할 수 있을까요?
### 2Phase Commit 알고리즘
![113822026-dd260d80-97b7-11eb-8ea8-b3c939d08cec](https://github.com/user-attachments/assets/cf5f158b-c4fb-4a19-afe7-94c619efda37)

- 여러 데이터베이스 노드에서 데이터를 읽고 쓴다.
- 커밋할 준비가 되면 코디네이터는 1단계를 시작한다. 각 노드에 준비 요청을 보내서 커밋 가능 여부를 묻는다.
- 모든 노드가 ‘예’ 라고 답하면 2단계에서 커밋 요청을 전송하고 커밋이 실제로 수행된다.
- 한 노드라도 ‘아니오’ 라고 답하면 코디네이터는 2단계의 모든 노드에 중단 요청을 보낸다.

**단점**
- 코디네이터의 오류가 발생하면 모든 트랜잭션이 코디네이터가 복구될 때까지 지연된다.
- 트랜잭션 실행 중 코디네이터에 문제가 생겨 응답을 받지 못하면 참가자 전체가 블로킹에 빠지게된다.

### Saga 패턴
최종 일관성을 바탕으로 둔 로컬 트랜잭션을 연속적으로 업데이트 수행하는 패턴

Saga 패턴의 종류
- Choreography-Based Saga
- Orchetration-Based Saga

**Choreography-Based Saga**
![img1 daumcdn 2](https://github.com/user-attachments/assets/d07fb8c3-c10e-406c-ad58-77faab9badc5)

- 자신이 보유한 서비스 내 DB만의 트랜잭션을 관리한다. 트랜잭션 종료 -> 완료 이벤트 발행
- 이어서 수행할 트랜잭션 존재시, 완료 이벤트 발행 후 해당 이벤트를 받은 애플리케이션에서 계속 트랜잭션을 수행
- 마지막에 도달하면 그 결과를 메인 애플리케이션에 전달하면 최종적으로 DB에 영속

**Rollback 상황**
![img1 daumcdn 3](https://github.com/user-attachments/assets/4174b357-8278-41e8-91c4-bc224263e7a0)

- 각 애플리케이션에서 트랜잭션 관리 로직 구현
- 중간에 트랜잭션이 실패하면 해당 트랜잭션 취소 처리를 실패한 애플리케이션에서 보상 Event 발행
- Rollback 처리

**Orchestration-Based**
![img1 daumcdn 4](https://github.com/user-attachments/assets/0890a991-8f93-498f-9e14-78155f44304a)


- 트랜잭션을 처리를 위한 인스턴스가 별도 존재
- 트랜잭션을 수행하는 모든 애플리케이션에서는 중앙 관리자에 의해 점진적으로 트랜잭션을 수행후 중앙관리자에게 결과를 전달
**트랜잭션 중도 실패**
- 중앙 관리자가 보상 트랜잭션 실행

## 마스터, 슬레이브 데이터 동기화 전 까지의 데이터 정합성을 지키는 방법은 무엇이 있을까요?

**Semi-Sync Replication**
Master DB에서 Slave 로 전달된 변경 내역이 Relay Log의 기록이 완료되었다는 신호(ACK)를 받고나서 처리중인 Transaction의 결과를 요청한 Client에 결과를 반환해주는 방식이다.
- Async 방식에 비의 클라이언트에 반환되는 응답 속도 성능이 조금 저하된다
- 데이터에 대한 정합성 측면에서는 더 보장해줄 수 있다.

![139540821-a5d17de9-80dd-4a42-9989-bbe6d8367e21](https://github.com/user-attachments/assets/a7e6ad0b-dd8a-479b-8db2-3be34286cd82)
데이터 정합성이 중요한 쿼리는 마스터 노드에서?
MySQL에서만 가능한 방법 아닌가?
따로 방법이 있나?

## 다중 트랜잭션 상황에서의 Deadlock 상황과, 이를 해결하기 위한 방법에 대해 설명해 주세요.
트랜잭션 A가 리소스 X를 점유하고 있고 리소스 Y를 요청하는 동안 트랜잭션 B가 리소스 Y를 점유하고 리소스 X를 요청하면 서로 대기 상태가 발생한다.

이를 해결하려면 Transaction Commit 또는 Rollback이 필요하다.

**회피**
Wait-die 방식
- 트랜잭션 A가 트랜잭션 B에 의해 락된 데이터를 요청할 때, 트랜잭션 A가 먼저 들어온 트랜잭션이라면 대기함
- 트랜잭션 A가 나중에 들어온 트랜잭션이면 포기하고 나중에 다시 요청함
Wound-wait 방식
- 트랜잭션 A가 트랜잭션 B보다 먼저 들어온 트랜잭션이면 데이터를 선점함
- 트랜잭션 A가 트랜잭션 B보다 나중에 들어온 트랜잭션이라면 대기함


타임아웃 설정
- 트랜잭션 대기 시간을 제한하여 일정 시간이 초과되면 트랜잭션을 강제로 종료하고 롤백한다.
  - MySQL - innodb_lock_wait_timeout 파라미터


> 뭔가 찾은 내용들이 이론적이라 주로 어떤 방법을 사용하는지 궁금

## 샤딩 방식은 무엇인가요? 만약 본인이 DB를 분산해서 관리해야 한다면, 레플리케이션 방식과 샤딩 방식 중 어떤 것을 사용할 것 같나요?
### 샤딩(Sharding)
데이터를 여러 개의 데이터베이스 서버에 분산해서 저장한다. 
<img width="1229" alt="스크린샷 2024-07-03 오후 12 16 51 2" src="https://github.com/user-attachments/assets/34a93a11-1e55-4589-aa6d-58c4105938c9" />

- 각 샤드는 독립적으로 운영되며, 전체 데이터베이스 시스템의 처리량과 성능을 향상시킨다.
- 샤딩의 핵심은 샤드 키를 어떻게 선택하느냐이다. 샤드 키는 데이터를 분할하고 분산 저장하는 기준이 되기때문에 샤딩의 성능과 효율성을 결정짓는 중요한 요소다

# 7. 정규화가 무엇인가요?

### 정규화란?
함수 종속성을 이용하여 릴레이션을 연관성이 있는 속성들로만 구성되도록 분해해서, **이상현상**이 발생하지 않는 올바른 릴레이션으로 만들어가는 과정을 정규화라고 한다.

## 정규화를 하지 않을 경우, 발생할 수 있는 이상현상에 대해 설명해 주세요.
### 이상현상
이상현상은 데이터베이스의 설계를 잘못하게 되었을 때, 불필요한 데이터 중복이 발생하여 릴레이션에 대한 데이터의 삽입, 갱신, 삭제 연산을 수행할 때 부작용이 발생하는 것을 말한다.

| **student_id** | **student_name** | **course_id** | **course_name** |
|---|---|---|---|
| 1 | Alice | 101 | Math |
| 1 | Alice | 102 | English |
| 2 | Bob | 101 | Math |
| 3 | Charlie | 103 | History |

### 삽입 이상
삽입 이상은 새로운 데이터를 삽입할 때 발생하는 문제이다. 특정 데이터를 삽입하기 위해 불필요한 정보까지 삽입해야 하거나, 필요한 데이터를 삽입할 수 없는 경우 발생한다.

**예시**
- 새로운 학생을 삽입할 때, 해당 학생이 수강하는 과목이 없다면 course_id, course_name 에 NULL 값을 삽입해야 한다.
- 새로운 과목을 넣을려면 해당과목을 수강하는 학생 정보도 함께 삽입해야 한다.
### 갱신 이상
갱신 이상은 데이터를 갱신할 때 발생하는 문제이다. 동일한 데이터가 여러 곳에 중복 저장되어 있어 한 곳만 갱신하면 데이터 불일치가 발생한다.

**예시**
- 한 학생이 여러 과목을 수강하는 경우 학생의 이름이 여러 레코드에 중복되어 저장된다.
- 학생의 이름을 변경할 때, 모든 레코드에서 일관되게 갱신되지 않으면 데이터 불일치가 발생한다.

### 삭제 이상
삭제 이상은 데이터를 삭제할 때 발생하는 문제이다. 특정 데이터를 삭제하면 의도치 않게 다른 중요한 데이터도 함께 삭제되는 경우이다.

**예시**
- 특정 과목을 삭제할 때, 그 과목을 수강하는 학생 정보도 삭제될 수 있다.
- 특정 학생을 삭제하면, 그 과목을 수강하는 모든 과목 정보도 함께 삭제된다.

## 각 정규화에 대해, 그 정규화가 진행되기 전/후의 테이블의 변화에 대해 설명해 주세요.

### 제 1 정규형(1NF)
릴레이션에 속한 모든 속성의 도메인의 **원자 값**으로만 구성되어 있으면 제1 정규형에 속한다.
**1NF 이전**
| **OrderID** | **Product** |
|---|---|
| 1 | Apple, Banana |
| 2 | Orange |

**1NF 이후**
| **OrderID** | **Product** |
|---|---|
| 1 | Apple |
| 1 | Banana |
| 2 | Orange |

### 제 2 정규형(2NF)
릴레이션이 제 1 정규형에 속하고, **기본키가 아닌 모든 속성이 기본키에 완전 함수 종속**되면 제 2 정규형에 속한다.
**2NF 이전**
| **OrderID** | **Product** | **SupplierID** | **SupplierName** |
|---|---|---|---|
| 1 | Apple | 100 | SupplierA |
| 1 | Banana | 101 | SupplierB |
| 2 | Orange | 100 | SupplierA |

**2NF 이후**
| **OrderID** | **Product** | **SupplierID** |
|---|---|---|
| 1 | Apple | 100 |
| 1 | Banana | 101 |
| 2 | Orange | 100 |

| **SupplierID** | **SupplierName** |
|---|---|
| 100 | SupplierA |
| 101 | SupplierB |
### 제 3 정규형(3NF)
릴레이션이 제 2 정규형에 속하고, **기본키가 아닌 모든 속성이 기본키에 이행적 함수 종속이 되지 않으면** 제 3 정규형에 속한다.

**이행적 함수 종속** : X -> Y, Y -> Z 가 성립할 때 논리적으로 X -> Z 성립한다. 이때 속성 집합 Z 가 속성 집합 X 에 이행적으로 함수 종속되었다고 한다.
**3NF 이전**
| **고객아이디** | **등급** | **할인율** |
|-----------|--------|---------|
| Apple     | gold   | 10%     |
| Banana    | vip    | 20%     |
| Orange    | silver | 5%      |

**3NF 이후**
| **고객아이디** | **등급** |
|-----------|--------|
| Apple     | gold   |
| Banana    | vip    |
| Orange    | silver |

| **등급** | **할인율** |
|--------|---------|
| gold   | 10%     |
| vip    | 20%     |
| silver | 5%      |

## 정규화가 무조건 좋은가요? 그렇지 않다면, 어떤 상황에서 역정규화를 하는게 좋은지 설명해 주세요.
정규화는 데이터베이스의 데이터 중복을 줄이고 데이터 무결성을 유지하는데 좋은 방법이다. 하지만 특정 상황에서는 성능 향샹과 더 쉬운 데이터 액세스를 위해 역정규화가 필요할 수 있다.

**정규화의 단점**
- 성능 저하 : 데이터가 여러 테이블로 분할되어 있어, 조회시 조인 연산이 많이 필요할 수 있어, 복잡한 쿼리가 생기고, 데이터베이스의 성능을 저하시킬 수 있다.

**역정규화가 유리한 상황**
1. 읽기 성능 최적화
   - 데이터베이스 읽기 연산이 매우 빈번하고, 쓰기 연산이 적은 경우 역정규화를 통해 읽기 성능을 향상시킬 수 있다.
2. 복잡한 조인 최소화
   - 여러 테이블 간의 조인이 빈번하게 발생하는 경우, 역졍규화를 통해 필요한 데이터를 하나의 테이블에 포함시켜 조인을 최소화할 수 있다.

#  8. View가 무엇이고, 언제 사용할 수 있나요?

### View 란
다른 테이블을 기반으로 만들어진 **가상 테이블**이다. 
뷰는 논리적으로만 존재하면서도 일반 테이블과 동일한 방법으로 사용할 수 있다.

### View 장점
- 쿼리문을 좀 더 쉽게 작성할 수 있다.
  - 특정 조건들을 만족하는 튜플들로 뷰를 미리 만들어놓으면 사용자가 특정 조건을 만족하는 데이터를 쉽게 검색할 수 있다.
- 데이터의 보안 유지에 도움이 된다.
  - 사용자의 요구에 맞는 다양한 뷰를 정의해두고, 사용자가 제공된 뷰를 통해서만 데이터를 접근하도록 권한을 설정하면 뷰에 포함되지 않는 데이터를 사용자로부터 보호할 수 있다.
- 데이터를 좀 더 편리하게 관리할 수 있다.
  - 제공된 뷰에 포함되지 않은 기본 테이블의 다른 부분은 사용자가 신경 쓸 필요가 없다.


## 그렇다면, View의 값을 수정해도 실제 테이블에는 반영되지 않나요?
INSERT, UPDATE, DELETE 문도 뷰를 대상으로 수행할 수 있다. 물론 뷰에 대한 삽입,수정,삭제 연산도 기본 테이블에 수행되기 때문에 결과적으로 기본 테이블이 변한다.
하지만, **삽입, 수정, 삭제 연산이 모든 뷰에 허용되는 것은 아니다**.

**변경이 불가능한 뷰의 주요 특징**
- 기본 테이블의 기본키를 구성하는 속성이 포함되어 있지 않은 뷰는 변경할 수 없다.
- 기본 테이블에 있던 내용이 아니라 집계 함수로 새로 계산된 내용을 포함하고 있는 뷰는 변경할 수 없다.
- DISTINCT 키워드를 포함하여 정의한 뷰는 변경할 수 없다.
- GROUP BY 절을 포함하여 정의한 뷰는 변경할 수 없다.
- 여러 개의 테이블을 조인하여 정의한 뷰는 변경할 수 없는 경우가 많다.

# 9. DB Join이 무엇인지 설명하고, 각각의 종류에 대해 설명해 주세요.
### Join
둘 이상의 테이블을 연결해서 데이터를 검색하는 방법이다. 주로 PK, FK로 두 테이블을 연결한다.

**종류**
- INNER JOIN
- LEFT OUTER JOIN
- RIGHT OUTER JOIN
- FULL OUTER JOIN
- CROSS JOIN
- SELF JOIN

![image 4](https://github.com/user-attachments/assets/b8dbcb35-762d-4055-8b68-9bc95ad22af1)

## 사실, JOIN은 상당한 시간이 걸릴 수 있기에 내부적으로 다양한 구현 방식을 사용하고 있습니다. 그 예시에 대해 설명해 주세요.
### Join 알고리즘

**Nested Loop Join**
- 두 테이블 중 하나를 외부 루프로 다른 하나를 내부 루프로 반복하면서 매칭되는 레코드를 찾는다.
- 작은 테이블과 큰 테이블을 JOIN 할 때 적합하다.
- 두 테이블의 크기가 커질수록 성능이 저하된다.
- 구동 테이블(outer loop)가 작은걸 선택해야 성능이 좋다. **단, inner table의 조인 키는 인덱스가 있어야 한다.**
![image 5](https://github.com/user-attachments/assets/bdda2ac7-c9a5-4e54-9394-d0f4ede0823a)

**Hash Join**
- 작은 테이블(보통 구동 테이블)의 조인 키 값을 기준으로 해시 테이블을 생성한다.
- 큰 테이블의 조인 키 값으로 해시 테이블을 탐색하여 조인한다.
- 조인 조건이 동등 비교일 때 효과적이다.
- 생성되는 해시 테이블의 크기가 너무 크면 오버헤드가 발생할 수 있다.

> MySQL employs a hash join for any query for which each join has an equi-join condition, and in which there are no indexes that can be applied to any join conditions, such as this one
조인 조건이 동등조건이고 조인 컬럼에 인덱스가 걸려있지않으면 해시조인을 사용한다.

**Sort-Merge Join**
- 두 테이블을 정렬한 후 병합하여 조인을 함
- 두 테이블이 정렬된 상태거나 정렬이 빠르게 수행될 수 있을 때 유용하다.
![image 6](https://github.com/user-attachments/assets/85b62514-a595-41a8-8338-4ef9b6806d70)
  
## 그렇다면 입력한 쿼리에서 어떤 구현 방식을 사용하는지는 어떻게 알 수 있나요?
실행 계획 확인을 통해서 알 수 있다.
`EXPLAIN SELECT * FROM A WHERE A.id = 5;`
## 앞 질문들을 통해 인덱스의 중요성을 알 수 있었는데, 그렇다면 JOIN의 성능도 인덱스의 유무의 영향을 받나요?
영향을 미친다.

Nested Loop Join 기준으로 총 접근되는 레코드 수는 A X B가 된다. 실행 시간을 A X B에 비례하게 된다.
성능을 높이려면 이 값을 낮춰야 한다.

조인 컬럼의 인덱스가 존재하는 경우


<img width="652" alt="스크린샷 2024-12-14 오후 4 47 09" src="https://github.com/user-attachments/assets/857abe7a-cc6c-470b-81cb-7bf183deb879" />

내부 테이블의 조인키에 인덱스가 존재하게 되면 모든 행에 대해 스캔을 할 필요가 없게 되므로 A X B의 값이 줄어든다.
Sort Merge Join 같은 경우 인덱스가 있으면 이미 정렬된 데이터로 볼 수 있기 때문에 추가 정렬 작업이 필요없어 성능을 높일 수 있다.

## 3중 조인 부터는 동작 방식이 약간 바뀝니다. 어떻게 동작하는지, 그리고 그 방식이 성능에 어떠한 영향을 주는지 설명해 주세요.
여러 개 테이블을 조인하더라도 두 개의 테이블 간에만 조인이 일어난다.
3개의 테이블을 조인한다면 2개의 테이블을 조인하고 그 결과를 나머지 1개의 테이블과 조인을 한다.
조인의 순서는 옵티마이저에 의해 결정된다.

**성능에 미치는 영향**
- 각 조인 결과마다 임시 테이블을 생성하기 때문에 메모리나 디스크 공간을 사용한다.
- 잘못된 조인 순서가 성능을 저하시킬 수 있다.
- 각 추가 조인마다 데이터의 크기가 크게 증가하므로 처리시간이 크게 늘어난다.

# 10. B-Tree와 B+Tree에 대해 설명해 주세요.	
### B-Tree
- Balanced-Tree -> 균형잡힌 트리
- 트리의 노드가 한 쪽으로만 몰리지 않도록 노드 삽입 및 삭제 시 특정 규칙에 맞게 재조정하여 전체적으로 균형을 유지한다.
### B+Tree
- B-Tree의 단점을 보완한 자료구조
  - B-Tree는 어떤 한 데이터의 검색에서는 빠르나 모든 데이터를 순회하기 위해서 리프 노드까지 갔다가 다시 부모 노드로 백트래킹하여 트리의 모든 노드를 방문해야 하므로 비효율적이다.
- 데이터는 리프 노드에만 저장한다.
- 리프 노드들은 링크드 리스트를 통해 서로 연결되어 있다.

**장점**
- 리프 노드를 제외한 노드에는 키만 저장하기 때문에 저장 공간을 절약할 수 있다.
- 연결된 리프 노드들에 대해서만 읽기를 진행하면 되므로 시간 단축이 된다.

## 그렇다면, B+Tree가 B-Tree에 비해 반드시 좋다고 할 수 있을까요? 그렇지 않다면 어떤 단점이 있을까요?

- 특정 키를 검색할 때 B+Tree는 리프 노드까지 탐색해야 하지만 B-Tree는 중간 노드에서 데이터를 찾을 수 있어 일부 더 빠를 수 있다.

## DB에서 RBT를 사용하지 않고, B-Tree/B+Tree를 사용하는 이유가 있을까요?
B-Tree/B+Tree는 한 개의 노드에 여러 개의 키들을 담을 수 있다. RBT는 한 개의 노드에 한 개의 키만 담을 수 있다. 이 때문에 B-Tree/B+Tree의 깊이가 RBT보다 낮다. 
-> 데이터를 찾을 때 빠르게 범위를 좁힐 수 있다.
-> Secondary Storage 접근을 더 적게할 수 있다.

B-Tree/B+Tree의 한 노드 안에서 물리적으로 연속된 공간에 데이터들이 저장되기 때문에 Block 단위의 조회에서 더 많은 유효데이터를 가져올 수 있다.
## 오름차순으로 정렬된 인덱스가 있다고 할 때, 내림차순 정렬을 시도할 경우 성능이 어떻게 될까요? B-Tree/B+Tree의 구조를 기반으로 설명해 주세요.
- **오름차순 인덱스** : 작은 값의 인덱스 키가 B-Tree 왼쪽 노드에 위치
- **내림차순 인덱스** : 큰 값의 인덱스 키가 B-Tree 왼쪽 노드에 위치
- **인덱스 정순 스캔** : 인덱스 키가 크고 작음에 관계없이 인덱스 리프노드의 왼쪽 페이지부터 오른쪽을 스캔
- **인덱스 역순 스캔** : 인덱스 키가 크고 작음에 관계없이 인덱스 리프노드의 오른쪽 페이지부터 왼쪽을 스캔

이름에 인덱스가 오름차순 인덱스로 걸려있다고 하자. 
`SELECT * FROM employees ORDER BY name DESC LIMIT 1;`

위 쿼리는 옵티마이저가 뒤에서 부터 읽는 것이 최적임을 알고 역순으로 레코드에 접근해서 읽어온다. 하지만 인덱스 역순 스캔은 정순 스캔보다 느리다.
- 페이지 잠금이 정순 스캔에 적합한 구조
- 페이지 내에서 인덱스 레코드는 단방향으로만 연결된 구조
[\[MySQL\] B-Tree로 인덱스\(Index\)에 대해 쉽고 완벽하게 이해하기](https://mangkyu.tistory.com/286)
https://tech.kakao.com/posts/351

# 11. DB Locking에 대해 설명해 주세요.	
### Lock
- 여러 커넥션에서 동시에 동일한 자원을 요청할 경우 순서대로 하나의 커넥션만 변경할 수 있게 해주는 기능
- 동시성을 제어하기 위한 기능
## Optimistic Lock/Pessimistic Lock에 대해 설명해 주세요.
### 낙관적 락
- 충돌이 거의 발생하지 않을 것이라고 가정하고, 충돌이 발생한 경우에 대비하는 방식
- 트랜잭션을 커밋하기 전까지는 충돌을 알 수 없음

**장점**
- 락으로 인한 성능저하가 적다.

### 비관적 락
- 충돌이 발생한다고 가정하고, 실제로 데이터에 접근하기 전에 우선 락을 걸어 충돌을 예방 하는 방법
**장점**
- 충돌 발생을 미리 방지하고 데이터의 일관성을 보장할 수 있다.

## 물리적인 Lock을 건다면, 만약 이를 수행중인 요청에 문제가 생겨 비정상 종료되면 Lock이 절대 해제되지 않는 문제가 생길 수도 있을 것 같습니다. DB는 이를 위한 해결책이 있나요? 없다면, 우리가 이 문제를 해결할 수 없을까요?

### DB 해결책
**innodb_deadlock_detect**
- 데드락 감지 스레드가 주기적으로 잠금 대기 그래프를 검사해서 데드락에 빠진 트랜잭션들을 찾아서 그 중 하나를 강제 종료한다.
- 언두 로그 레코드를 더 적게 가진 트랜잭션을 일반적으로 종료 시킨다.

**innodb_lock_wait_timeout**
- 데드락 상황에서 일정 시간이 지나면 자동으로 요청이 실패하고 에러 메시지를 반환한다.

**우리의 해결책**
# 12. 트래픽이 높아질 때, DB는 어떻게 관리를 할 수 있을까요?
### DB 서버를 분산해서 트래픽을 감당하는 방법

**샤딩(Sharding)**
데이터를 여러 개의 데이터베이스 서버에 분산해서 저장한다. 

<img width="1229" alt="스크린샷 2024-07-03 오후 12 16 51" src="https://github.com/user-attachments/assets/15c89bbc-adde-4e39-9a91-5538d4bdb0b5" />

- 각 샤드는 독립적으로 운영되며, 전체 데이터베이스 시스템의 처리량과 성능을 향상시킨다.
- 샤딩의 핵심은 샤듀 키를 어떻게 선택하느냐이다. 샤드 키는 데이터를 분할하고 분산 저장하는 기준이 되기때문에 샤딩의 성능과 효율성을 결정짓는 중요한 요소다
### 레플리케이션(Replication)
동일한 데이터를 여러 데이터베이스 서버에 복제한다. 주로 읽기 성능을 향상시키기 위해 사용된다.

![3](https://github.com/user-attachments/assets/1c1caabb-1749-463b-82b6-3cb66aa12174)

- Master 에는 쓰기 요청만 반영하고 Slave 에 Replication 을 해서 실제 데이터를 복사한다.
- Slave 는 Master 서버로부터 복제된 데이터를 받아서 읽기 요청에 대한 작업을 한다.
이를 통해 Read(Select) 성능 향상을 시킬 수 있다.

### 로드 밸런싱(Load Balancing)

로그 밸런서를 이용해서 데이터베이스 서버에 대한 트래픽을 균등하게 분산한다.

## DB 서버를 분산하지 않고, 트래픽을 감당할 수 있는 방법

### 파티셔닝(Partitioning)
데이터베이스 테이블을 더 작은 테이블들로 나누는 것이다.

- vertical partitioning : column 을 기준으로 테이블을 나누는 방식
- horizontal partitioning : row 를 기준으로 테이블을 나누는 방식

**수직 파티셔닝(vertical partitioning)**
- 모든 컬럼들 중 특정 컬럼들을 나눠서 따로 저장하는 방법
- 수직 파티셔닝을 정규화 과정과 비슷한 개념이라고 생각하면 이해하기 쉽다.

<img width="884" alt="스크린샷 2024-07-03 오후 12 51 36" src="https://github.com/user-attachments/assets/2c3374c6-d55a-47c3-919d-222207696586" />
<img width="1047" alt="스크린샷 2024-07-03 오후 12 52 03" src="https://github.com/user-attachments/assets/b4183777-23f1-4f44-90af-168803893cee" />

**장점**
자주 사용하는 컬럼 등을 분리시켜 성능을 향상 시킬 수 있다.

**수평 파티셔닝(horizontal partitioning)**
- 하나의 테이블의 각 행을 다른 테이블로 분산하는 것이다.
- Key 기반으로 여러 곳에 분산 저장한다.
<img width="436" alt="스크린샷 2024-07-03 오후 12 55 01" src="https://github.com/user-attachments/assets/317a3ea4-5e37-4d5c-b303-a51fc1a9dda5" />
<img width="423" alt="스크린샷 2024-07-03 오후 12 57 19" src="https://github.com/user-attachments/assets/3ab90146-3ee3-49b6-bd3a-a794fd350f9c" />

**장점**
데이터의 개수가 작아지고 index 의 개수도 작아진다. -> 성능 향상

### 쿼리 최적화
- 인덱스 사용 : 자주 조회되는 컬럼에 적절한 인덱스를 추가하여 쿼리 성능을 향상시킨다.
- 쿼리 리팩토링 : 복잡한 쿼리를 간소화하고, 불필요한 조인과 서브 쿼리를 제거한다.
- 배치 쿼리 사용 : 다수의 작은 쿼리를 하나의 배치로 처리하여 데이터베이스 부하를 줄인다.

### 캐싱
- 애플리케이션 캐시 : 자주 조회되는 데이터를 애플리케이션 레벨에서 캐싱한다.(Redis)
- 쿼리 결과 캐싱 : 동일한 쿼리에 대해 결과를 캐싱하여 데이터베이스 부하를 줄인다.

# 13. Schema가 무엇인가요
Schema 는 데이터베이스에 저장되는 데이터 구조와 제약조건을 정의한 것이다.

예를 들어, 고객과 관련된 데이터인 고객번호, 이름, 나이, 주소를 저장한다고 가정하고, 고객번호는 정수로 이름은 최대 10자의 문자열로 나이는 정수로 주소는 최대 20자의 문자열로 한다고하면 이 모든 내용이 스키마다.

## Schema의 3계층에 대해 설명해주세요

외부 스키마, 개념 스키마, 내부 스키마가 있다.

### 외부 스키마
**사용자나 응용 프로그램이 데이터베이스를 어떻게 볼 것인가를 정의한다**. 하나의 데이터베이스를 조직 내의 사용자들이 함께 사용하지만 각 사용자가 데이터베이스 전체에 관심이 있는 것은 아니다.

그렇기 때문에 사용자마다 생각하는 데이터베이스의 구조가 다르다. 이처럼 사용자에게 필요한 데이터베이스를 정의한 것을 외부 스키마라고 한다.

데이터베이스 하나의 외부 스키마가 여러 개 존재할 수 있고, 외부 스키마 하나를 사용 목적이 같은 사용자들이 공유할 수 있다.

### 개념 스키마
데이터베이스의 전체 구조를 정의한다. **데이터베이스의 논리적 관점에서 모든 데이터를 통합하여 표현한다.**
모든 개별 사용자가 생각하는 데이터베이스의 모습을 하나로 합친 형태이다.

데이터베이스 하나에는 하나의 개념 스키마만 존재하고, 각 사용자는 개념 스키마의 일부분을 사용한다.

### 내부 스키마
내부 스키마는 **데이터베이스의 물리적 저장 구조를 정의한다.** 이는 데이터가 실제로 데이터베이스에 저장되는 방식을 다룬다.

전체 데이터베이스가 저장 장치에 실제로 저장되는 방법을 정의하는 것을 내부 스키마라 한다.
![img1 daumcdn](https://github.com/user-attachments/assets/1813fd11-6441-4e08-b5cf-a6253175faf0)

# DB의 Connection Pool에 대해 설명해 주세요!
<img width="1032" alt="스크린샷 2024-07-08 오후 6 15 13" src="https://github.com/user-attachments/assets/cedfe5e2-4028-42d6-b62f-6b6d17cd403e" />


사용자가 요청을 할 때마다 Connection 을 열고 닫는 것은 매우 비효율적이다. 이 문제를 해결하기 위해서 Connection Pool 을 사용한다.
<img width="2015" alt="스크린샷 2024-07-08 오후 6 17 14" src="https://github.com/user-attachments/assets/f2b579b3-e76c-4aba-83df-ece8775136c2" />

### Connection Pool 설정방법
**DB 서버 설정**
- max_connections : client 와 맺을 수 있는 최대 connection 수
- wait_timeout : connection 이 inactive 할 때 다시 요청이 오기까지 얼마의 시간을 기다린 뒤에 close 할 것인지를 결정
**DBCP 설정**
- minimunldle : connection pool 에서 유지하는 최소한의 idle connection 수
  - HikariCP 문서에는 minimunldle 의 기본값은 maximumPoolSize 와 동일하다.
  - 동일하게 사용하는 것을 권장한다.
- maximumPoolSize : connection pool 이 가지는 최대 connection(idle + active) 의 수
- maxLifetime : connection pool 에서 connection의 최대 수명
  - maxLifetime 을 넘긴 idle connection 을 connection pool 에서 제거하고, active 일 경우 pool 로 반환된 후 제거한다.
- connectionTimeout : connection pool에서 connection을 받기 위한 대기 시간


# Table Full Scan, Index Range Scan에 대해 설명해 주세요.
## Table Full Scan
특정 테이블의 모든 행을 순차적으로 읽어서 필요한 데이터를 찾는 방식이다.

- 테이블의 대부분 또는 모든 데이터를 읽어야하는 경우, 또는 인덱스를 사용할 수 없는 경우에 사용된다.
- 시퀀셜 액세스 + Multi Block I/O
## Index Range Scan
인덱스를 사용하여 특정 범위 내에 데이터를 검색하는 방식이다. 
인덱스는 데이터가 정렬된 구조로 되어 있어 특정 조건에 맞는 데이터를 효율적으로 찾을 수 있다.

- 범위 검색 또는 조건 검색이 필요한 경우, 해당 컬럼에 인덱스가 존재하는 경우에 사용된다.
- 랜덤 액세스 + Single Block I/O

## Index Range Scan 이 Table Full Scan 보다 항상 성능이 좋을까?
이 질문에 대한 답은 아니다.
 
데이터가 정렬되어 있는 트리구조라서 검색효율은 매우 좋다. 하지만 쿼리를 통해 얻을려고 하는 정보들이 인덱스에 모두 포함되어 있지 않다면 Index scan 을 한 후 얻어진 ROWID 를 통해 테이블을 접근해야 한다.

age 컬럼이 인덱스로 생성되어 있다.
```sql
SELECT *
FROM student
WHERE age > 18;
```

Index scan 을 통해서 age 값을 확인 했지만 해당 레코드에 포함되어 있는 모든 컬럼을 조회해야 하기 떄문에 ROWID 를 통해 테이블에 접근해서 나머지 정보를 확인해야 한다. 이 과정을 랜덤 액세스라고 한다.

랜덤 액세스의 비용은 많이 든다. 그래서 Index Range Scan 에는 손익분기점이라는 것이 존재한다.
일반적으로 전체 데이터의 5~20% 를 검색할 때까지 이다. 이 손익분기점을 넘어서서 랜덤 액세스의 비율이 높아지게 되면 Index Range Scan 보다 Table Full Scan 이 더 좋은 상황이 될 수 있다.

그리고 많은 데이터(5~20%) 를 조회할 때 Table Full Scan 이 더 유리한 이유는 ROWID 에 의한 테이블 액세스가 Index Range Scan 은 Single Block I/O 이고 Table Full Scan 은 Multi Block I/O 방식이기 때문인다.

# 가끔은 인덱스를 타는 쿼리임에도 Table Full Scan 방식으로 동작하는 경우가 있습니다. 왜 그럴까요?

## 데이터 분포와 선택도
전체 테이블의 많은 행을 반환하는 경우
```sql
SELECT * FROM employees WHERE status = 'active';
```
## 인덱스 부적절성
order_date 에 인덱스가 있으나, 인덱스가 오래되었거나 비효율적인 경우.
```sql
SELECT * FROM orders WHERE order_date = '2023-01-01';
```
## **시스템 자원 문제**
메모리가 부족하여 Full Scan이 더 나은 경우
```sql
SELECT * FROM large_table;
```

이러한 상황에서 옵티마이저는 인덱스 대신 Table Full Scan을 선택할 수 있다.

# COUNT (개수를 세는 쿼리) 는 어떻게 동작하나요? COUNT(1), COUNT(*), COUNT(column) 의 동작 과정에는 차이가 있나요?

## COUNT(1)
조건을 만족하는 행의 개수를 센다. 여기서 1은 단순히 상수로, 각 행마다 1이 반환되기 때문에, 실제로는 조건을 만족하는 모든 행을 카운트한다.

테이블의 각 행을 순회하면서 ‘1’ 을 반환하고 그 수를 센다.

COUNT(1)과 COUNT(*)의 성능 차이는 거의 없다. 두 쿼리 모두 최적화되어 동일한 실행 계획을 사용하는 경우가 많다.
## COUNT(*)
COUNT(*)은 조건을 만족하는 모든 행의 개수를 센다. 테이블의 모든 행을 포함하며, 널(NULL) 값도 포함된다.

테이블의 각 행을 순회하면서 모든 행을 카운트한다. 특정 컬럼을 지정하지 않기 때문에, 옵티마이저는 가능한 최적의 방식으로 전체 행을 센다.

일반적으로 가장 효율적인 방법으로 간주된다. 모든 행을 카운트하므로 특정 컬럼의 널 값 여부를 신경 쓰지 않는다.
## COUNT(column)

COUNT(column)은 지정된 컬럼에서 널(NULL) 값이 아닌 행의 개수를 센다. 특정 컬럼에 대해 널이 아닌 값만 카운트한다.

테이블의 각 행을 순회하면서, 지정된 컬럼의 값이 널이 아닌 경우에만 카운트합니다.

컬럼에 널 값이 있는지 여부에 따라 결과가 달라진다. 특정 컬럼의 값을 기준으로 개수를 세고자 할 때 유용하다.

### 성능 및 최적화
* COUNT(1) vs COUNT(*): 일반적으로 성능 차이는 거의 없다. 현대적인 DBMS는 두 쿼리를 동일하게 최적화한다.
* COUNT(column): 특정 컬럼에 널 값이 많은 경우, COUNT(column)은 COUNT(*)보다 성능이 떨어질 수 있다. 하지만, 널 값을 제외하고 카운트해야 하는 경우라면 필요하다.

#  SQL Injection에 대해 설명해 주세요.

##  SQL Injection
악의적인 사용자가 웹 애플리케이션의 데이터베이스 쿼리를 조작하여 비정상적인 동작을 유도하거나, 데이터를 탈취하거나, 변경하거나, 삭제하는 등의 공격 기법이다.

애플리케이션이 사용자로부터 입력받은 데이터를 제대로 검증하지 않고 SQL 쿼리를 직접 포함시킬 때 발생한다.

## 원리
SQL Injection 공격자는 SQL 쿼리에 삽입될 데이터를 조작하여 쿼리의 구조를 변경한다. 이를 통해 정상적인 쿼리를 비정상적인 쿼리로 변환하고, 데이터베이스에 대한 권한을 획득하거나 민감한 데이터를 조회할 수 있다.

## 예시
로그인을 할 때 아이디와 비밀번호를 input 창에 입력하게 된다. 
```sql
SELECT * FROM user WHERE ID = "abc" AND PASSWORD = "1234";
```

SQL Injection으로 공격할 때, input 창에 비밀번호를 입력함과 동시에 다른 쿼리문을 함께 입력하는 것이다.
```sql
1234; DELETE * USER FROM ID = "1";
```

보안이 완벽하지 않은 경우 뒤에 작성한 DELETE 문도 데이터베이스에 영향을 줄 수 있게 된다.

다른 예시로는 WHERE 절에 OR 문을 추가해서 `‘1’ = ‘1’` 과 같은 true 문을 작성하여 무조건 적용되도록 수정한 뒤 DB 를 조작할 수 있다.

# 그렇다면, 우리가 서버 개발 과정에서 사용하는 수많은 DB 라이브러리들은 이 문제를 어떻게 해결할까요?

## Prepared Statements
preparestatement를 사용하면, 특수문자를 자동으로 escaping 해준다. (statement와는 다르게 쿼리문에서 전달인자 값을 ?로 받는 것) 이를 활용해 서버 측에서 필터링 과정을 통해서 공격을 방어한다.. 

## 작동 원리
1. **쿼리 준비(Preparation)**: SQL 쿼리의 구조를 데이터베이스 서버에 전달하고, 이를 컴파일한다.
2. **파라미터 바인딩(Binding)**: 실행 시점에 쿼리에 필요한 실제 값을 제공하고, 컴파일된 쿼리에 바인딩한다.
3. **쿼리 실행(Execution)**: 바인딩된 파라미터와 함께 쿼리를 실행한다.


